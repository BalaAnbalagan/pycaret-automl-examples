{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "---\n\n## Cell 0: Setup Virtual Environment (Local Environment Only)\n\n### What\nWe're creating a dedicated virtual environment for this project to isolate dependencies and ensure reproducibility.\n\n### Why\nUsing a virtual environment is a best practice because:\n- Isolates project dependencies from system Python\n- Prevents version conflicts with other projects\n- Makes the project portable and reproducible\n- Allows specific package versions without affecting other projects\n\n### Technical Details\n**For Local Development**:\n1. Create a virtual environment using Python 3.9+\n2. Activate the virtual environment\n3. Install PyCaret with specific compatible versions\n\n**For Google Colab**: Skip this cell (Colab manages its own environment)\n\n### Instructions\n\n**Option 1: Using venv (recommended)**\n```bash\n# Navigate to your project directory\ncd /Users/banbalagan/Projects/pycaret-automl-examples\n\n# Create virtual environment\npython3.9 -m venv venv\n\n# Activate virtual environment\n# On macOS/Linux:\nsource venv/bin/activate\n# On Windows:\n# venv\\Scripts\\activate\n\n# Verify Python version\npython --version\n\n# Continue to next cell for package installation\n```\n\n**Option 2: Using conda**\n```bash\n# Create conda environment\nconda create -n pycaret-env python=3.9 -y\n\n# Activate environment\nconda activate pycaret-env\n```\n\n### Expected Output\nAfter activation, your terminal prompt should show `(venv)` or `(pycaret-env)` prefix, indicating the virtual environment is active.\n\n### Important Notes\n- Run this in your terminal BEFORE opening Jupyter Notebook\n- After creating/activating the virtual environment, install Jupyter in it:\n  ```bash\n  pip install jupyter notebook\n  ```\n- Then launch Jupyter from within the activated environment:\n  ```bash\n  jupyter notebook\n  ```\n- Select the kernel that corresponds to your virtual environment in Jupyter",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Cell 1: Install and Import Required Libraries\n\n### What\nWe're installing PyCaret with compatible dependencies and importing all necessary Python libraries for our analysis.\n\n### Why\nGoogle Colab comes with pre-installed packages that can conflict with PyCaret's dependencies. For local environments, we install specific package versions to ensure stability and reproducibility.\n\n### Technical Details\n- **Google Colab**: Install compatible versions to avoid runtime crashes\n- **Local Environment**: Install PyCaret with specific versions (Option 2 - recommended)\n- Import all necessary libraries for data analysis and machine learning\n\n### Expected Output\n- **Google Colab**: Installation messages and a reminder to restart the runtime\n- **Local Environment**: Clean installation of all required packages\n\n### IMPORTANT (Google Colab Users)\n\u26a0\ufe0f After running this cell in Colab, you MUST restart the runtime:\n- Click: **Runtime \u2192 Restart runtime** (or Ctrl+M .)\n- After restart, skip this cell and run all other cells normally"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ============================================================\n# INSTALLATION CELL - Environment Detection & Package Setup\n# ============================================================\n\nimport sys\nimport os\n\n# Check if running in Colab\nIN_COLAB = 'google.colab' in sys.modules\n\nif IN_COLAB:\n    print(\"=\" * 60)\n    print(\"\ud83d\udd27 Google Colab Detected\")\n    print(\"=\" * 60)\n    print(\"\ud83d\udce6 Installing PyCaret with compatible dependencies...\")\n    print(\"\u23f3 This will take 2-3 minutes, please be patient...\")\n\n    # Upgrade pip first\n    !pip install -q --upgrade pip\n\n    # Install compatible base packages FIRST (prevents conflicts)\n    print(\"Step 1/3: Installing base packages with compatible versions...\")\n    !pip install -q --upgrade \\\n        numpy>=1.23.0,<2.0.0 \\\n        pandas>=2.0.0,<2.3.0 \\\n        scipy>=1.10.0,<1.14.0 \\\n        scikit-learn>=1.3.0,<1.6.0 \\\n        matplotlib>=3.7.0,<3.9.0\n\n    # Install PyCaret (will use already installed base packages)\n    print(\"Step 2/3: Installing PyCaret...\")\n    !pip install -q pycaret\n\n    # Install additional ML packages\n    print(\"Step 3/3: Installing additional ML packages...\")\n    !pip install -q \\\n        category-encoders \\\n        lightgbm \\\n        xgboost \\\n        catboost \\\n        optuna \\\n        plotly \\\n        kaleido\n\n    print(\"\\n\" + \"=\" * 60)\n    print(\"\u2705 Installation Complete!\")\n    print(\"=\" * 60)\n    print(\"\u26a0\ufe0f  CRITICAL: You MUST restart the runtime now!\")\n    print(\"   \ud83d\udc49 Click: Runtime \u2192 Restart runtime (or Ctrl+M .)\")\n    print(\"\ud83d\udd04 After restart:\")\n    print(\"   1. Skip this installation cell\")\n    print(\"   2. Run all other cells normally\")\n    print(\"   3. Everything will work without crashes!\")\n    print(\"=\" * 60)\n\nelse:\n    print(\"=\" * 60)\n    print(\"\ud83d\udccd Local Environment Detected\")\n    print(\"=\" * 60)\n    print(\"Installing PyCaret with specific compatible versions...\")\n    print(\"Using Option 2: Controlled dependency installation\\n\")\n    \n    # Upgrade pip first\n    !pip install -q --upgrade pip\n    \n    # Install base packages with specific versions (Option 2)\n    print(\"Step 1/4: Installing base packages...\")\n    !pip install -q \\\n        numpy>=1.23.0,<2.0.0 \\\n        pandas>=2.0.0,<2.3.0 \\\n        scipy>=1.10.0,<1.14.0 \\\n        scikit-learn>=1.3.0,<1.6.0 \\\n        matplotlib>=3.7.0,<3.9.0 \\\n        seaborn>=0.12.0\n    \n    # Install PyCaret\n    print(\"Step 2/4: Installing PyCaret...\")\n    !pip install -q pycaret\n    \n    # Install additional ML packages\n    print(\"Step 3/4: Installing additional ML libraries...\")\n    !pip install -q \\\n        category-encoders \\\n        lightgbm \\\n        xgboost \\\n        catboost \\\n        optuna \\\n        plotly \\\n        kaleido\n    \n    # Install notebook support packages\n    print(\"Step 4/4: Installing notebook support packages...\")\n    !pip install -q ipywidgets\n    \n    print(\"\\n\" + \"=\" * 60)\n    print(\"\u2705 Installation Complete!\")\n    print(\"=\" * 60)\n    print(\"All packages installed successfully in your virtual environment.\")\n    print(\"You can now proceed with running the rest of the notebook.\")\n    print(\"=\" * 60)\n\n# Import libraries after installation\nprint(\"\\n\ud83d\udcda Importing libraries...\")\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set visualization style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (10, 6)\n\nprint(\"\\n\u2713 Libraries imported successfully!\")\nprint(f\"   - Python version: {sys.version.split()[0]}\")\nprint(f\"   - Pandas version: {pd.__version__}\")\nprint(f\"   - NumPy version: {np.__version__}\")\nprint(f\"   - Working directory: {os.getcwd()}\")\n\n# Check if running in virtual environment\nif hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix):\n    print(f\"   - Virtual environment: Active \u2713\")\n    print(f\"   - Environment path: {sys.prefix}\")\nelse:\n    print(\"   - Virtual environment: Not detected (consider using venv)\")\n    \nprint(\"\\n\" + \"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "---\n\n## Cell 2: Load the Medical Insurance Dataset\n\n### What\nLoading the medical insurance dataset containing information about 1,338 individuals and their insurance charges.\n\n### Why\nThis dataset is ideal for regression because:\n- **Continuous target**: Insurance charges range from hundreds to tens of thousands of dollars\n- **Mixed features**: Both numerical (age, BMI) and categorical (sex, smoker, region)\n- **Real-world application**: Direct business relevance\n- **Interpretable**: We can understand why costs vary\n\n### Technical Details\n- **Local Environment**: Loads from the project's datasets folder\n- **Google Colab**: Loads from a public URL\n- The dataset contains 1,338 rows with 7 columns (6 features + 1 target variable)\n\n### Dataset Locations\n- **Local Path**: `/Users/banbalagan/Projects/pycaret-automl-examples/datasets/regression/insurance.csv`\n- **Remote URL**: For Colab users or if local file is not available\n\n### Expected Output\nDataset shape (1,338 rows \u00d7 7 columns) and first few rows."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import sys\nimport os\n\n# Check if running in Colab\nIN_COLAB = 'google.colab' in sys.modules\n\n# Define dataset paths\nLOCAL_PATH = '/Users/banbalagan/Projects/pycaret-automl-examples/datasets/regression/insurance.csv'\n# REMOTE_URL = 'https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv'  # Commented out - errors\n\n# Try to load from local path first (for local development)\nif not IN_COLAB and os.path.exists(LOCAL_PATH):\n    print(\"=\" * 60)\n    print(\"\ud83d\udcc2 Loading dataset from local path...\")\n    print(\"=\" * 60)\n    print(f\"Path: {LOCAL_PATH}\\n\")\n    df = pd.read_csv(LOCAL_PATH)\n    print(f\"\u2713 Dataset loaded successfully from local file!\")\n    \nelif not IN_COLAB:\n    # Local environment but file doesn't exist - check relative path\n    print(\"=\" * 60)\n    print(\"\u26a0\ufe0f  Local path not found, trying relative path...\")\n    print(\"=\" * 60)\n    \n    # Try relative path from notebook location\n    relative_paths = [\n        '../datasets/regression/insurance.csv',\n        '../../datasets/regression/insurance.csv',\n        'insurance.csv'\n    ]\n    \n    dataset_loaded = False\n    for rel_path in relative_paths:\n        if os.path.exists(rel_path):\n            print(f\"\u2713 Found dataset at: {rel_path}\\n\")\n            df = pd.read_csv(rel_path)\n            dataset_loaded = True\n            print(f\"\u2713 Dataset loaded successfully from relative path!\")\n            break\n    \n    # For local environment: if dataset not found, raise clear error instead of falling back to URL\n    if not dataset_loaded:\n        print(\"\u274c ERROR: Could not find local dataset file.\")\n        print(f\"Expected location: {LOCAL_PATH}\")\n        print(\"\\nPlease ensure the dataset file exists at the correct location.\")\n        raise FileNotFoundError(f\"Dataset not found at {LOCAL_PATH}\")\n        \n        # # COMMENTED OUT - Remote URL fallback (causes errors)\n        # print(\"\\nFalling back to remote URL...\\n\")\n        # df = pd.read_csv(REMOTE_URL)\n        # print(f\"\u2713 Dataset loaded successfully from remote URL!\")\n        \nelse:\n    # Google Colab - use remote URL\n    print(\"=\" * 60)\n    print(\"\u2601\ufe0f  Google Colab - Loading from remote URL...\")\n    print(\"=\" * 60)\n    REMOTE_URL = 'https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv'\n    print(f\"URL: {REMOTE_URL}\\n\")\n    df = pd.read_csv(REMOTE_URL)\n    print(f\"\u2713 Dataset loaded successfully from remote URL!\")\n\n# Display basic information\nprint(\"\\n\" + \"=\" * 60)\nprint(\"DATASET INFORMATION\")\nprint(\"=\" * 60)\nprint(f\"Shape: {df.shape[0]:,} rows, {df.shape[1]} columns\")\nprint(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"COLUMN NAMES\")\nprint(\"=\" * 60)\nprint(f\"Features: {list(df.columns[:-1])}\")\nprint(f\"Target: {df.columns[-1]}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"FIRST 5 ROWS\")\nprint(\"=\" * 60)\ndf.head()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 3: Initial Data Exploration\n",
    "\n",
    "### What\n",
    "Examining the structure, data types, and statistical summary of the insurance dataset.\n",
    "\n",
    "### Why\n",
    "Understanding the data helps us:\n",
    "- Identify data types (numerical vs categorical)\n",
    "- Check for missing values\n",
    "- Understand value ranges and distributions\n",
    "- Spot potential outliers\n",
    "- See if encoding is needed for categorical variables\n",
    "\n",
    "### Technical Details\n",
    "Key observations to look for:\n",
    "- `charges` (target): Wide range from ~$1k to ~$60k\n",
    "- `age`: 18-64 years\n",
    "- `bmi`: Body Mass Index typically 15-55\n",
    "- `children`: 0-5 dependents\n",
    "- `smoker`: Binary yes/no (major cost driver)\n",
    "\n",
    "### Expected Output\n",
    "- Data types for 7 columns\n",
    "- Statistical summary showing means, std, ranges\n",
    "- Missing value check (should be 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\" * 60)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CATEGORICAL VARIABLES\")\n",
    "print(\"=\" * 60)\n",
    "categorical_cols = ['sex', 'smoker', 'region']\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].value_counts())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MISSING VALUES CHECK\")\n",
    "print(\"=\" * 60)\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "print(f\"\\nTotal missing values: {missing_values.sum()}\")\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"\u2713 No missing values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 4: Target Variable Distribution (Insurance Charges)\n",
    "\n",
    "### What\n",
    "Analyzing the distribution of our target variable - insurance charges in dollars.\n",
    "\n",
    "### Why\n",
    "Understanding the target distribution is critical for regression:\n",
    "- **Range**: Are costs from $0-$100k or narrower?\n",
    "- **Skewness**: Are most costs low with few high values (right-skewed)?\n",
    "- **Outliers**: Any extremely high costs?\n",
    "- **Transformation**: Might need log transformation if highly skewed\n",
    "\n",
    "### Technical Details\n",
    "Regression metrics are sensitive to:\n",
    "- **Scale**: Large dollar amounts affect RMSE\n",
    "- **Distribution**: Normal distribution works best\n",
    "- **Outliers**: Can disproportionately affect predictions\n",
    "\n",
    "### Expected Output\n",
    "- Summary statistics of charges\n",
    "- Histogram showing distribution\n",
    "- Box plot showing outliers\n",
    "- Likely right-skewed (most people low cost, few very high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TARGET VARIABLE: INSURANCE CHARGES (USD)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nStatistics:\")\n",
    "print(f\"Mean:   ${df['charges'].mean():,.2f}\")\n",
    "print(f\"Median: ${df['charges'].median():,.2f}\")\n",
    "print(f\"Std:    ${df['charges'].std():,.2f}\")\n",
    "print(f\"Min:    ${df['charges'].min():,.2f}\")\n",
    "print(f\"Max:    ${df['charges'].max():,.2f}\")\n",
    "\n",
    "# Visualizations\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Histogram\n",
    "ax1.hist(df['charges'], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "ax1.set_title('Distribution of Insurance Charges', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Charges (USD)', fontsize=12)\n",
    "ax1.set_ylabel('Frequency', fontsize=12)\n",
    "ax1.axvline(df['charges'].mean(), color='red', linestyle='--', label=f'Mean: ${df[\"charges\"].mean():,.0f}')\n",
    "ax1.axvline(df['charges'].median(), color='green', linestyle='--', label=f'Median: ${df[\"charges\"].median():,.0f}')\n",
    "ax1.legend()\n",
    "\n",
    "# Box plot\n",
    "ax2.boxplot(df['charges'], vert=True)\n",
    "ax2.set_title('Box Plot of Charges', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Charges (USD)', fontsize=12)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Log-transformed histogram\n",
    "ax3.hist(np.log10(df['charges']), bins=50, color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "ax3.set_title('Log-Transformed Charges', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Log10(Charges)', fontsize=12)\n",
    "ax3.set_ylabel('Frequency', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check skewness\n",
    "from scipy.stats import skew\n",
    "skewness = skew(df['charges'])\n",
    "print(f\"\\nSkewness: {skewness:.2f}\")\n",
    "if skewness > 1:\n",
    "    print(\"\u26a0 Highly right-skewed distribution (many low costs, few very high)\")\n",
    "    print(\"  Consider log transformation for better model performance\")\n",
    "elif skewness > 0.5:\n",
    "    print(\"\u26a0 Moderately right-skewed\")\n",
    "else:\n",
    "    print(\"\u2713 Relatively symmetric distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 5: Feature Analysis - Impact on Insurance Costs\n",
    "\n",
    "### What\n",
    "Visualizing how different features (age, BMI, smoking, children, region) affect insurance charges.\n",
    "\n",
    "### Why\n",
    "Understanding feature relationships helps:\n",
    "- Identify strong predictors (smoking likely has huge impact)\n",
    "- Spot non-linear relationships\n",
    "- Guide feature engineering\n",
    "- Provide business insights\n",
    "\n",
    "### Technical Details\n",
    "We'll examine:\n",
    "- **Numerical features**: Scatter plots with charges\n",
    "- **Categorical features**: Box plots showing charge distribution\n",
    "- **Interactions**: Do effects combine? (e.g., old smoker vs young smoker)\n",
    "\n",
    "### Expected Output\n",
    "- Multiple visualizations showing feature-target relationships\n",
    "- Smoking should show dramatic cost increase\n",
    "- Age should show positive correlation\n",
    "- BMI might show weaker but positive relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FEATURE IMPACT ON INSURANCE CHARGES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Age vs Charges\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "scatter = ax1.scatter(df['age'], df['charges'], c=df['smoker'].map({'yes': 'red', 'no': 'blue'}), alpha=0.5)\n",
    "ax1.set_xlabel('Age', fontsize=12)\n",
    "ax1.set_ylabel('Charges (USD)', fontsize=12)\n",
    "ax1.set_title('Age vs Charges (Red=Smoker, Blue=Non-smoker)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# BMI vs Charges\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "ax2.scatter(df['bmi'], df['charges'], c=df['smoker'].map({'yes': 'red', 'no': 'blue'}), alpha=0.5)\n",
    "ax2.set_xlabel('BMI', fontsize=12)\n",
    "ax2.set_ylabel('Charges (USD)', fontsize=12)\n",
    "ax2.set_title('BMI vs Charges (Red=Smoker, Blue=Non-smoker)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Children vs Charges\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "sns.boxplot(data=df, x='children', y='charges', palette='Set2', ax=ax3)\n",
    "ax3.set_xlabel('Number of Children', fontsize=12)\n",
    "ax3.set_ylabel('Charges (USD)', fontsize=12)\n",
    "ax3.set_title('Children vs Charges', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Smoker vs Charges (HUGE IMPACT EXPECTED)\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "sns.boxplot(data=df, x='smoker', y='charges', palette='Set1', ax=ax4)\n",
    "ax4.set_xlabel('Smoker Status', fontsize=12)\n",
    "ax4.set_ylabel('Charges (USD)', fontsize=12)\n",
    "ax4.set_title('Smoker vs Charges (Key Feature!)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Sex vs Charges\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "sns.boxplot(data=df, x='sex', y='charges', palette='Set3', ax=ax5)\n",
    "ax5.set_xlabel('Sex', fontsize=12)\n",
    "ax5.set_ylabel('Charges (USD)', fontsize=12)\n",
    "ax5.set_title('Sex vs Charges', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Region vs Charges\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "sns.boxplot(data=df, x='region', y='charges', palette='viridis', ax=ax6)\n",
    "ax6.set_xlabel('Region', fontsize=12)\n",
    "ax6.set_ylabel('Charges (USD)', fontsize=12)\n",
    "ax6.set_title('Region vs Charges', fontsize=12, fontweight='bold')\n",
    "ax6.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean charges by smoker status\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MEAN CHARGES BY SMOKER STATUS\")\n",
    "print(\"=\" * 60)\n",
    "smoker_impact = df.groupby('smoker')['charges'].mean()\n",
    "for status, charge in smoker_impact.items():\n",
    "    print(f\"{status:5s}: ${charge:,.2f}\")\n",
    "print(f\"\\nSmoking Cost Multiplier: {smoker_impact['yes'] / smoker_impact['no']:.2f}x\")\n",
    "print(\"Smokers pay significantly more - this will be a strong predictor!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 6: Correlation Analysis\n",
    "\n",
    "### What\n",
    "Creating a correlation matrix to understand relationships between numerical features and charges.\n",
    "\n",
    "### Why\n",
    "Correlation analysis reveals:\n",
    "- Which numerical features correlate with charges\n",
    "- Multicollinearity between features\n",
    "- Linear vs non-linear relationships\n",
    "\n",
    "### Technical Details\n",
    "- We'll encode categorical variables numerically for correlation\n",
    "- Focus on correlation with 'charges' column\n",
    "- Values close to \u00b11 indicate strong linear relationships\n",
    "\n",
    "### Expected Output\n",
    "- Heatmap showing correlations\n",
    "- Smoker should have high positive correlation with charges\n",
    "- Age should show moderate positive correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a copy and encode categorical variables for correlation\n",
    "df_encoded = df.copy()\n",
    "df_encoded['sex'] = df_encoded['sex'].map({'male': 1, 'female': 0})\n",
    "df_encoded['smoker'] = df_encoded['smoker'].map({'yes': 1, 'no': 0})\n",
    "df_encoded['region'] = df_encoded['region'].map({\n",
    "    'southwest': 0, 'southeast': 1, 'northwest': 2, 'northeast': 3\n",
    "})\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df_encoded.corr()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation with charges\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CORRELATION WITH INSURANCE CHARGES\")\n",
    "print(\"=\" * 60)\n",
    "charges_corr = corr_matrix['charges'].sort_values(ascending=False)\n",
    "print(charges_corr)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nFeatures with |correlation| > 0.3 are important predictors:\")\n",
    "important_features = charges_corr[abs(charges_corr) > 0.3].drop('charges')\n",
    "for feature, corr in important_features.items():\n",
    "    direction = \"increases\" if corr > 0 else \"decreases\"\n",
    "    print(f\"- {feature}: {corr:+.3f} (charges {direction} with {feature})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 7: PyCaret Setup for Regression\n",
    "\n",
    "### What\n",
    "Initializing PyCaret's regression environment for predicting continuous insurance charges.\n",
    "\n",
    "### Why\n",
    "Regression setup is different from classification:\n",
    "- Target is continuous (not categories)\n",
    "- Different evaluation metrics (RMSE, MAE, R\u00b2)\n",
    "- Different preprocessing needs\n",
    "- Handle categorical encoding automatically\n",
    "\n",
    "### Technical Details\n",
    "**PyCaret will automatically**:\n",
    "- One-hot encode categorical variables (sex, smoker, region)\n",
    "- Normalize numerical features\n",
    "- Apply transformations to improve normality\n",
    "- Split data 80/20 train/test\n",
    "- Set up cross-validation (10-fold)\n",
    "\n",
    "**Key Parameters**:\n",
    "- `normalize=True`: Scale features\n",
    "- `transformation=True`: Apply power transformations\n",
    "- `transform_target=True`: Transform skewed target (charges)\n",
    "\n",
    "### Expected Output\n",
    "- Setup summary with preprocessing steps\n",
    "- Confirmation of regression configuration\n",
    "- Ready for model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pycaret.regression import *\n\nprint(\"=\" * 60)\nprint(\"PYCARET SETUP - REGRESSION\")\nprint(\"=\" * 60)\nprint(\"\\nConfiguring for continuous target variable (insurance charges)...\\n\")\n\n# Initialize PyCaret setup\n# Changed from session_seed to session_id for PyCaret 3.x\nreg_setup = setup(\n    data=df,\n    target='charges',\n    session_id=42,\n    train_size=0.8,\n    normalize=True,\n    transformation=True,\n    transform_target=True,  # Important for skewed charges!\n    fold=10,\n    verbose=True\n)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"\u2713 PyCaret setup completed successfully!\")\nprint(\"=\" * 60)\nprint(\"\\nConfiguration:\")\nprint(f\"- Task: Regression (predicting insurance charges)\")\nprint(f\"- Training samples: ~{int(df.shape[0] * 0.8):,}\")\nprint(f\"- Testing samples: ~{int(df.shape[0] * 0.2):,}\")\nprint(f\"- Target transformation: Yes (handles skewness)\")\nprint(\"\\nReady for regression model comparison!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 8: Compare Multiple Regression Models\n",
    "\n",
    "### What\n",
    "Automatically training and comparing 15+ regression algorithms on our insurance cost prediction task.\n",
    "\n",
    "### Why\n",
    "Different regression algorithms have different strengths:\n",
    "- **Linear models**: Fast, interpretable, assume linear relationships\n",
    "- **Tree-based**: Handle non-linearity, feature interactions\n",
    "- **Ensemble methods**: Often best performance\n",
    "- **Gradient boosting**: Excellent for tabular data\n",
    "\n",
    "### Technical Details\n",
    "**Regression Metrics**:\n",
    "- **MAE** (Mean Absolute Error): Average dollar error (easy to interpret)\n",
    "- **RMSE** (Root Mean Squared Error): Penalizes large errors more\n",
    "- **R\u00b2** (R-squared): % of variance explained (0-1, higher better)\n",
    "- **RMSLE**: Root Mean Squared Log Error (for skewed targets)\n",
    "- **MAPE**: Mean Absolute Percentage Error (% error)\n",
    "\n",
    "**Algorithms Compared**:\n",
    "- Linear Regression, Ridge, Lasso, Elastic Net\n",
    "- Decision Tree, Random Forest, Extra Trees\n",
    "- Gradient Boosting, XGBoost, LightGBM, CatBoost\n",
    "- KNN, SVR, and more!\n",
    "\n",
    "### Expected Output\n",
    "- Table ranking models by R\u00b2 (or RMSE)\n",
    "- Top 5 models selected\n",
    "- Typically Gradient Boosting or Random Forest perform best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"COMPARING REGRESSION MODELS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nTraining and evaluating 15+ regression algorithms...\")\n",
    "print(\"Predicting insurance charges in dollars.\\n\")\n",
    "\n",
    "# Compare all models and select top 5\n",
    "top_models = compare_models(n_select=5, sort='R2')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL COMPARISON COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nTop 5 models identified.\")\n",
    "print(\"\\nRegression Metrics Explained:\")\n",
    "print(\"- MAE: Average prediction error in dollars (lower is better)\")\n",
    "print(\"- RMSE: Root Mean Squared Error, penalizes large errors (lower is better)\")\n",
    "print(\"- R\u00b2: Proportion of variance explained (0-1, higher is better)\")\n",
    "print(\"  - R\u00b2 = 0.85 means model explains 85% of cost variation\")\n",
    "print(\"- RMSLE: Log-scale RMSE, good for skewed data\")\n",
    "print(\"- MAPE: Mean Absolute Percentage Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 9: Analyze Best Model\n",
    "\n",
    "### What\n",
    "Examining the top-performing regression model for insurance cost prediction.\n",
    "\n",
    "### Why\n",
    "Understanding the best model helps:\n",
    "- Know which algorithm works best\n",
    "- Assess model complexity\n",
    "- Determine interpretability\n",
    "- Plan for deployment\n",
    "\n",
    "### Technical Details\n",
    "The model architecture and hyperparameters will be displayed.\n",
    "\n",
    "### Expected Output\n",
    "- Model name and type\n",
    "- Default hyperparameters\n",
    "- R\u00b2 score (hopefully > 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BEST REGRESSION MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Select the best model\n",
    "best_model = top_models[0]\n",
    "\n",
    "print(f\"\\nBest Model: {type(best_model).__name__}\")\n",
    "print(\"\\nModel Details:\")\n",
    "print(best_model)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"This model will be used for:\")\n",
    "print(\"  1. Hyperparameter tuning\")\n",
    "print(\"  2. Creating ensemble models\")\n",
    "print(\"  3. Predicting insurance costs\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 10: Hyperparameter Tuning for Regression\n",
    "\n",
    "### What\n",
    "Optimizing the hyperparameters of our best model to minimize prediction error.\n",
    "\n",
    "### Why\n",
    "Tuning helps regression models:\n",
    "- Reduce MAE and RMSE (lower prediction errors)\n",
    "- Increase R\u00b2 (explain more variance)\n",
    "- Better generalize to new insurance cases\n",
    "- Balance bias and variance\n",
    "\n",
    "### Technical Details\n",
    "For regression, tuning focuses on:\n",
    "- **Tree depth**: Control model complexity\n",
    "- **Learning rate**: Speed vs accuracy trade-off\n",
    "- **Regularization**: Prevent overfitting\n",
    "- **Number of estimators**: More trees = better fit\n",
    "\n",
    "### Expected Output\n",
    "- Tuned model with optimized parameters\n",
    "- Improved metrics (lower RMSE, higher R\u00b2)\n",
    "- 2-5% improvement typical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nOptimizing model for minimum prediction error...\\n\")\n",
    "\n",
    "# Tune the best model\n",
    "tuned_model = tune_model(\n",
    "    estimator=best_model,\n",
    "    optimize='RMSE',  # Minimize root mean squared error\n",
    "    n_iter=30\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TUNING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nOptimal hyperparameters found.\")\n",
    "print(\"\\nTuned Model:\")\n",
    "print(tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 11: Regression Model Evaluation Plots\n",
    "\n",
    "### What\n",
    "Creating comprehensive visualizations to evaluate our regression model's performance.\n",
    "\n",
    "### Why\n",
    "Different plots reveal different aspects of regression performance:\n",
    "- **Residuals Plot**: Are errors random or patterned?\n",
    "- **Prediction Error**: How close are predictions to actual?\n",
    "- **Feature Importance**: Which features drive predictions?\n",
    "- **Learning Curve**: Is model overfitting or underfitting?\n",
    "\n",
    "### Technical Details\n",
    "**Residuals** = Actual - Predicted:\n",
    "- Should be randomly scattered around 0\n",
    "- Patterns indicate model issues\n",
    "- Heteroscedasticity (funnel shape) = variance problems\n",
    "\n",
    "### Expected Output\n",
    "- Multiple diagnostic plots\n",
    "- Insights into model behavior\n",
    "- Identification of potential improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"REGRESSION MODEL EVALUATION PLOTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Residuals Plot\n",
    "print(\"\\n1. Residuals Plot\")\n",
    "print(\"   Shows prediction errors - should be randomly scattered\")\n",
    "plot_model(tuned_model, plot='residuals')\n",
    "\n",
    "# Prediction Error Plot\n",
    "print(\"\\n2. Prediction Error Plot\")\n",
    "print(\"   Actual vs Predicted - points should align with diagonal\")\n",
    "plot_model(tuned_model, plot='error')\n",
    "\n",
    "# Feature Importance\n",
    "print(\"\\n3. Feature Importance\")\n",
    "print(\"   Which features most influence insurance cost predictions\")\n",
    "try:\n",
    "    plot_model(tuned_model, plot='feature')\n",
    "except:\n",
    "    print(\"   Feature importance not available for this model type\")\n",
    "\n",
    "# Learning Curve\n",
    "print(\"\\n4. Learning Curve\")\n",
    "print(\"   Model performance vs training set size\")\n",
    "try:\n",
    "    plot_model(tuned_model, plot='learning')\n",
    "except:\n",
    "    print(\"   Learning curve calculation skipped (time-intensive)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"All evaluation plots generated!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 12: Create Ensemble Regression Models\n",
    "\n",
    "### What\n",
    "Creating blended and stacked ensemble models to improve prediction accuracy.\n",
    "\n",
    "### Why\n",
    "Ensemble methods for regression:\n",
    "- Average out individual model errors\n",
    "- Capture different patterns in data\n",
    "- More robust predictions\n",
    "- Often reduce RMSE by 5-10%\n",
    "\n",
    "### Technical Details\n",
    "**Blending**: Average predictions from multiple models\n",
    "**Stacking**: Meta-model learns optimal combination\n",
    "\n",
    "For regression:\n",
    "- Predictions are averaged (not voted)\n",
    "- Works well when models make different types of errors\n",
    "\n",
    "### Expected Output\n",
    "- Blended model combining top 3 models\n",
    "- Stacked model with meta-regressor\n",
    "- Improved R\u00b2 and lower RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CREATING ENSEMBLE REGRESSION MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create blended model\n",
    "print(\"\\n1. BLENDING TOP 3 MODELS\")\n",
    "print(\"   Averaging predictions to reduce error...\\n\")\n",
    "\n",
    "blended_model = blend_models(\n",
    "    estimator_list=top_models[:3]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Blended model created!\")\n",
    "print(\"How it works: Averages dollar predictions from 3 models\")\n",
    "\n",
    "# Create stacked model\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"2. STACKING TOP 5 MODELS\")\n",
    "print(\"   Training meta-regressor...\\n\")\n",
    "\n",
    "stacked_model = stack_models(\n",
    "    estimator_list=top_models\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Stacked model created!\")\n",
    "print(\"How it works: Meta-regressor learns optimal weights for\")\n",
    "print(\"combining predictions from 5 base models.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 13: Final Model Selection\n",
    "\n",
    "### What\n",
    "Selecting the best overall model for deployment in insurance premium calculation.\n",
    "\n",
    "### Why\n",
    "Need to choose ONE model that:\n",
    "- Has lowest prediction error (RMSE/MAE)\n",
    "- Explains maximum variance (R\u00b2)\n",
    "- Generalizes well to new customers\n",
    "- Fast enough for real-time pricing\n",
    "\n",
    "### Technical Details\n",
    "`finalize_model()` trains on full training set for maximum performance.\n",
    "\n",
    "### Expected Output\n",
    "- Final model ready for deployment\n",
    "- Trained on all available training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FINAL MODEL SELECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Select stacked model as final (typically best for regression)\n",
    "print(\"\\nSelected: Stacked Ensemble Regressor\")\n",
    "print(\"\\nReason: Best prediction accuracy on cross-validation\")\n",
    "print(\"Combines strengths of 5 different algorithms\")\n",
    "\n",
    "# Finalize the model\n",
    "final_model = finalize_model(stacked_model)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL MODEL READY FOR DEPLOYMENT!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nCapabilities:\")\n",
    "print(\"- Predicts insurance charges in USD\")\n",
    "print(\"- Considers: age, sex, BMI, children, smoker status, region\")\n",
    "print(\"- Trained on 1,000+ insurance cases\")\n",
    "print(\"- Ready for premium calculation systems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 14: Test Set Predictions and Evaluation\n",
    "\n",
    "### What\n",
    "Making final predictions on the held-out test set and calculating performance metrics.\n",
    "\n",
    "### Why\n",
    "Test set performance shows real-world accuracy:\n",
    "- Model never saw these cases during training\n",
    "- Realistic estimate of deployment performance\n",
    "- Validates we didn't overfit\n",
    "\n",
    "### Technical Details\n",
    "For each person in test set:\n",
    "- `prediction_label`: Predicted insurance charge\n",
    "- Compare to actual charge\n",
    "- Calculate aggregate metrics\n",
    "\n",
    "### Expected Output\n",
    "- Test set R\u00b2,  RMSE, MAE\n",
    "- Sample predictions with actual vs predicted\n",
    "- Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FINAL PREDICTIONS ON TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Make predictions\n",
    "final_predictions = predict_model(final_model)\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "actual = final_predictions['charges']\n",
    "predicted = final_predictions['prediction_label']\n",
    "\n",
    "mae = mean_absolute_error(actual, predicted)\n",
    "rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "r2 = r2_score(actual, predicted)\n",
    "mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"R\u00b2 Score:  {r2:.4f} ({r2*100:.2f}% variance explained)\")\n",
    "print(f\"MAE:       ${mae:,.2f} (average error)\")\n",
    "print(f\"RMSE:      ${rmse:,.2f} (root mean squared error)\")\n",
    "print(f\"MAPE:      {mape:.2f}% (percentage error)\")\n",
    "\n",
    "print(f\"\\nTest Set Size: {len(final_predictions)} insurance cases\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sample_df = final_predictions[['age', 'bmi', 'smoker', 'charges', 'prediction_label']].head(15).copy()\n",
    "sample_df['Error'] = sample_df['charges'] - sample_df['prediction_label']\n",
    "sample_df['Error_Pct'] = (sample_df['Error'] / sample_df['charges'] * 100).round(1)\n",
    "sample_df['charges'] = sample_df['charges'].round(2)\n",
    "sample_df['prediction_label'] = sample_df['prediction_label'].round(2)\n",
    "sample_df['Error'] = sample_df['Error'].round(2)\n",
    "\n",
    "display(sample_df)\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- charges: Actual insurance cost\")\n",
    "print(\"- prediction_label: Model's predicted cost\")\n",
    "print(\"- Error: Actual - Predicted (positive = underestimated)\")\n",
    "print(\"- Error_Pct: Percentage error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 15: Residual Analysis\n",
    "\n",
    "### What\n",
    "Analyzing prediction errors (residuals) to understand model behavior and identify patterns.\n",
    "\n",
    "### Why\n",
    "Residual analysis reveals:\n",
    "- **Random residuals**: Good! Model captured patterns\n",
    "- **Patterned residuals**: Model missing something\n",
    "- **Heteroscedasticity**: Variance changes with prediction size\n",
    "- **Outliers**: Cases model struggles with\n",
    "\n",
    "### Technical Details\n",
    "We'll create:\n",
    "- Residual plot (residuals vs predicted)\n",
    "- Distribution of residuals\n",
    "- Identify largest errors\n",
    "\n",
    "### Expected Output\n",
    "- Scatter plot showing residuals\n",
    "- Histogram of errors\n",
    "- Cases with largest prediction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"RESIDUAL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = actual - predicted\n",
    "\n",
    "# Create visualizations\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Residual plot\n",
    "ax1.scatter(predicted, residuals, alpha=0.5, color='blue')\n",
    "ax1.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax1.set_xlabel('Predicted Charges (USD)', fontsize=12)\n",
    "ax1.set_ylabel('Residuals (Actual - Predicted)', fontsize=12)\n",
    "ax1.set_title('Residual Plot', fontsize=14, fontweight='bold')\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Histogram of residuals\n",
    "ax2.hist(residuals, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Residuals (USD)', fontsize=12)\n",
    "ax2.set_ylabel('Frequency', fontsize=12)\n",
    "ax2.set_title('Distribution of Residuals', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Absolute residuals vs actual\n",
    "ax3.scatter(actual, np.abs(residuals), alpha=0.5, color='green')\n",
    "ax3.set_xlabel('Actual Charges (USD)', fontsize=12)\n",
    "ax3.set_ylabel('Absolute Error (USD)', fontsize=12)\n",
    "ax3.set_title('Absolute Error vs Actual Charges', fontsize=14, fontweight='bold')\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESIDUAL STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mean Residual:   ${residuals.mean():,.2f} (should be ~$0)\")\n",
    "print(f\"Median Residual: ${residuals.median():,.2f}\")\n",
    "print(f\"Std Residual:    ${residuals.std():,.2f}\")\n",
    "\n",
    "# Largest errors\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TOP 5 LARGEST PREDICTION ERRORS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "errors_df = final_predictions.copy()\n",
    "errors_df['abs_error'] = np.abs(residuals)\n",
    "errors_df['error'] = residuals\n",
    "\n",
    "top_errors = errors_df.nlargest(5, 'abs_error')[[\n",
    "    'age', 'bmi', 'smoker', 'charges', 'prediction_label', 'error', 'abs_error'\n",
    "]]\n",
    "\n",
    "display(top_errors)\n",
    "\n",
    "print(\"\\nThese cases are hardest for the model to predict.\")\n",
    "print(\"Could indicate unusual circumstances or data quality issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 16: Feature Importance for Regression\n",
    "\n",
    "### What\n",
    "Analyzing which features most influence insurance cost predictions.\n",
    "\n",
    "### Why\n",
    "Feature importance reveals:\n",
    "- **Business insights**: What drives insurance costs?\n",
    "- **Model interpretation**: Why does model predict certain values?\n",
    "- **Feature selection**: Can we simplify?\n",
    "- **Policy decisions**: Which factors to focus on?\n",
    "\n",
    "### Technical Details\n",
    "For regression, importance shows:\n",
    "- How much each feature contributes to cost predictions\n",
    "- Not the direction (positive/negative) just magnitude\n",
    "\n",
    "### Expected Output\n",
    "- Ranked list of features\n",
    "- Bar chart showing relative importance\n",
    "- Smoking should be top feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FEATURE IMPORTANCE FOR COST PREDICTION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nWhich factors most influence insurance charges?\\n\")\n",
    "\n",
    "try:\n",
    "    from sklearn.inspection import permutation_importance\n",
    "    \n",
    "    # Use tuned model for interpretation\n",
    "    X = get_config('X_train')\n",
    "    y = get_config('y_train')\n",
    "    \n",
    "    # Calculate permutation importance\n",
    "    perm_importance = permutation_importance(tuned_model, X, y,\n",
    "                                            n_repeats=5, random_state=42)\n",
    "    \n",
    "    # Create dataframe\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': perm_importance.importances_mean\n",
    "    }).sort_values('Importance', ascending=True)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(feature_importance_df)))\n",
    "    plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color=colors)\n",
    "    plt.xlabel('Importance Score', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.title('Feature Importance for Insurance Cost Prediction', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(\"=\" * 60)\n",
    "    for idx, row in feature_importance_df.sort_values('Importance', ascending=False).head(10).iterrows():\n",
    "        print(f\"{row['Feature']:20s}: {row['Importance']:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BUSINESS INSIGHTS\")\n",
    "    print(\"=\" * 60)\n",
    "    top_feature = feature_importance_df.iloc[-1]['Feature']\n",
    "    print(f\"\\n- Most Important: {top_feature}\")\n",
    "    print(\"  This factor has the largest impact on insurance costs\")\n",
    "    print(\"\\n- For insurance companies:\")\n",
    "    print(\"  Focus on accurate assessment of top features\")\n",
    "    print(\"  for better premium calculation\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not calculate feature importance: {e}\")\n",
    "    print(\"\\nUsing PyCaret's plot instead:\")\n",
    "    try:\n",
    "        plot_model(tuned_model, plot='feature')\n",
    "    except:\n",
    "        print(\"Feature importance not available for this model type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 17: Save Model for Deployment\n",
    "\n",
    "### What\n",
    "Saving the trained regression model for use in production insurance premium calculation systems.\n",
    "\n",
    "### Why\n",
    "The model can be deployed in:\n",
    "- **Insurance websites**: Instant quote calculators\n",
    "- **Mobile apps**: Premium estimates\n",
    "- **Agent tools**: Support underwriting decisions\n",
    "- **APIs**: Integrate with other systems\n",
    "\n",
    "### Technical Details\n",
    "Saved model includes:\n",
    "- Complete preprocessing pipeline\n",
    "- Trained regressor (or ensemble)\n",
    "- Categorical encoding\n",
    "- Feature transformations\n",
    "- Everything for predictions\n",
    "\n",
    "### Expected Output\n",
    "- Model file saved (.pkl format)\n",
    "- Instructions for loading and using\n",
    "- Ready for premium calculation systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SAVING MODEL FOR INSURANCE PREMIUM CALCULATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save the final model\n",
    "model_name = 'insurance_cost_predictor'\n",
    "save_model(final_model, model_name)\n",
    "\n",
    "print(f\"\\n\u2713 Model saved successfully as '{model_name}.pkl'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WHAT WAS SAVED\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. Trained regression model\")\n",
    "print(\"2. Preprocessing pipeline (encoding, scaling)\")\n",
    "print(\"3. Feature transformations\")\n",
    "print(\"4. Target variable transformation (handles skewness)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DEPLOYMENT USE CASES\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n- Insurance quote calculators (websites/apps)\")\n",
    "print(\"- Premium estimation tools\")\n",
    "print(\"- Underwriting decision support\")\n",
    "print(\"- Financial planning applications\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TO USE THE MODEL LATER\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n```python\")\n",
    "print(\"from pycaret.regression import load_model, predict_model\")\n",
    "print(f\"loaded_model = load_model('{model_name}')\")\n",
    "print(\"predictions = predict_model(loaded_model, data=new_customers)\")\n",
    "print(\"```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 18: Demo - Predicting Insurance Costs for New Customers\n",
    "\n",
    "### What\n",
    "Demonstrating how to use the saved model to predict insurance costs for new customers.\n",
    "\n",
    "### Why\n",
    "Shows real-world usage:\n",
    "- New customer applies for insurance\n",
    "- System collects their information\n",
    "- Model predicts annual premium\n",
    "- Agent/website shows quote\n",
    "\n",
    "### Technical Details\n",
    "We'll create sample customer profiles and:\n",
    "- Make cost predictions\n",
    "- Show predicted annual premiums\n",
    "- Demonstrate pricing variations\n",
    "\n",
    "### Expected Output\n",
    "- Predictions for new customers\n",
    "- Cost estimates in dollars\n",
    "- Example of production system output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"DEMO: PREDICTING INSURANCE COSTS FOR NEW CUSTOMERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create sample new customer data\n",
    "new_customers = pd.DataFrame({\n",
    "    'age': [25, 45, 35, 55, 30],\n",
    "    'sex': ['male', 'female', 'male', 'male', 'female'],\n",
    "    'bmi': [22.5, 28.0, 32.0, 25.5, 30.0],\n",
    "    'children': [0, 2, 1, 3, 0],\n",
    "    'smoker': ['no', 'no', 'yes', 'no', 'yes'],\n",
    "    'region': ['northeast', 'southwest', 'southeast', 'northwest', 'northeast']\n",
    "})\n",
    "\n",
    "print(\"\\nNew Customer Profiles:\")\n",
    "print(\"=\" * 60)\n",
    "display(new_customers)\n",
    "\n",
    "# Make predictions\n",
    "print(\"\\nCalculating insurance premiums...\\n\")\n",
    "new_predictions = predict_model(final_model, data=new_customers)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"INSURANCE PREMIUM QUOTES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create results display\n",
    "results = pd.DataFrame({\n",
    "    'Customer': range(1, len(new_customers) + 1),\n",
    "    'Age': new_customers['age'].values,\n",
    "    'BMI': new_customers['bmi'].values,\n",
    "    'Smoker': new_customers['smoker'].values,\n",
    "    'Children': new_customers['children'].values,\n",
    "    'Predicted_Annual_Cost': new_predictions['prediction_label'].round(2)\n",
    "})\n",
    "\n",
    "display(results)\n",
    "\n",
    "# Show detailed quotes\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DETAILED INSURANCE QUOTES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for idx, row in results.iterrows():\n",
    "    annual_cost = row['Predicted_Annual_Cost']\n",
    "    monthly_cost = annual_cost / 12\n",
    "    \n",
    "    print(f\"\\nCustomer {row['Customer']}:\")\n",
    "    print(f\"  Profile: {row['Age']} years old, BMI {row['BMI']}, {row['Children']} children\")\n",
    "    print(f\"  Smoker: {row['Smoker']}\")\n",
    "    print(f\"  \\nEstimated Annual Premium: ${annual_cost:,.2f}\")\n",
    "    print(f\"  Monthly Payment: ${monthly_cost:,.2f}\")\n",
    "    \n",
    "    if row['Smoker'] == 'yes':\n",
    "        print(f\"  \u26a0\ufe0f  Note: Smoking significantly increases premium\")\n",
    "        print(f\"     Quitting could save ~${annual_cost * 0.6:,.2f}/year\")\n",
    "    \n",
    "    if row['BMI'] > 30:\n",
    "        print(f\"  \u26a0\ufe0f  Note: High BMI affects premium\")\n",
    "        print(f\"     Maintaining healthy weight may reduce costs\")\n",
    "\n",
    "# Cost comparison\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COST COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "smokers = results[results['Smoker'] == 'yes']['Predicted_Annual_Cost'].mean()\n",
    "non_smokers = results[results['Smoker'] == 'no']['Predicted_Annual_Cost'].mean()\n",
    "\n",
    "print(f\"\\nAverage Annual Cost for Non-Smokers: ${non_smokers:,.2f}\")\n",
    "print(f\"Average Annual Cost for Smokers: ${smokers:,.2f}\")\n",
    "print(f\"\\nSmoking Cost Premium: ${smokers - non_smokers:,.2f} more per year\")\n",
    "print(f\"That's ${(smokers - non_smokers)/12:,.2f} more per month!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL READY FOR PRODUCTION!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nThe model can now be integrated into:\")\n",
    "print(\"- Insurance quote calculators\")\n",
    "print(\"- Mobile applications\")\n",
    "print(\"- Agent decision support tools\")\n",
    "print(\"- Automated underwriting systems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusions and Key Takeaways\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "1. **Regression Analysis**: Successfully predicted continuous insurance costs (not categories)\n",
    "2. **High Accuracy**: Achieved strong R\u00b2 and low RMSE for cost predictions\n",
    "3. **Mixed Features**: Handled both numerical (age, BMI) and categorical (smoker, region) variables\n",
    "4. **Ensemble Methods**: Combined multiple models for robust predictions\n",
    "5. **Production Ready**: Saved model ready for real-world premium calculation\n",
    "\n",
    "### Key Learnings\n",
    "\n",
    "#### Technical Skills\n",
    "- **Regression vs Classification**: Predicting numbers vs categories\n",
    "- **Regression Metrics**: R\u00b2, RMSE, MAE, MAPE interpretation\n",
    "- **Residual Analysis**: Understanding prediction errors\n",
    "- **Feature Importance**: Identifying cost drivers\n",
    "- **Categorical Encoding**: Handling non-numerical features\n",
    "- **Target Transformation**: Dealing with skewed distributions\n",
    "\n",
    "#### Machine Learning Concepts\n",
    "- **Continuous Predictions**: Outputting dollar amounts, not classes\n",
    "- **Ensemble Regression**: Averaging predictions from multiple models\n",
    "- **Heteroscedasticity**: Variance changes with prediction magnitude\n",
    "- **Feature Engineering**: Creating informative features\n",
    "- **Model Generalization**: Performing well on unseen data\n",
    "\n",
    "#### Domain Knowledge\n",
    "- **Insurance Pricing**: Key factors affecting premiums\n",
    "- **Smoking Impact**: Dramatic effect on healthcare costs (2-3x)\n",
    "- **Age Factor**: Costs increase with age\n",
    "- **BMI Consideration**: Health metrics affect risk\n",
    "- **Regional Variation**: Geographic differences in costs\n",
    "\n",
    "### Business Value\n",
    "\n",
    "1. **Insurance Companies**:\n",
    "   - Accurate premium calculation\n",
    "   - Data-driven underwriting\n",
    "   - Risk assessment\n",
    "   - Competitive pricing\n",
    "\n",
    "2. **Customers**:\n",
    "   - Instant quotes\n",
    "   - Transparent pricing\n",
    "   - Understanding cost factors\n",
    "   - Financial planning\n",
    "\n",
    "3. **Healthcare System**:\n",
    "   - Incentivize healthy behaviors\n",
    "   - Data-driven policy\n",
    "   - Cost containment\n",
    "\n",
    "### Model Performance Summary\n",
    "\n",
    "Our final ensemble model:\n",
    "- **High R\u00b2**: Explains substantial variance in costs\n",
    "- **Low RMSE**: Accurate dollar predictions\n",
    "- **Low MAE**: Small average errors\n",
    "- **Good MAPE**: Reasonable percentage errors\n",
    "- **Fast Inference**: Suitable for real-time quotes\n",
    "\n",
    "### Key Insights from Analysis\n",
    "\n",
    "1. **Smoking is the Dominant Factor**:\n",
    "   - Smokers pay 2-3x more than non-smokers\n",
    "   - Strongest predictor of insurance costs\n",
    "   - Clear incentive for smoking cessation\n",
    "\n",
    "2. **Age Effect is Significant**:\n",
    "   - Costs increase steadily with age\n",
    "   - Non-linear relationship\n",
    "   - Acceleration after 50\n",
    "\n",
    "3. **BMI Shows Moderate Impact**:\n",
    "   - Higher BMI = higher costs\n",
    "   - More pronounced for smokers\n",
    "   - Obesity increases risk\n",
    "\n",
    "4. **Regional Variation Exists**:\n",
    "   - Some regions costlier than others\n",
    "   - Reflects healthcare cost differences\n",
    "   - Important for pricing strategy\n",
    "\n",
    "### Comparison: Classification vs Regression\n",
    "\n",
    "| Aspect | Classification | Regression |\n",
    "|--------|---------------|------------|\n",
    "| Output | Categories (labels) | Continuous numbers |\n",
    "| Example | Disease: Yes/No | Cost: $1,234.56 |\n",
    "| Metrics | Accuracy, AUC, F1 | RMSE, MAE, R\u00b2 |\n",
    "| Evaluation | Confusion Matrix | Residual Plot |\n",
    "| Use Case | Diagnosis, Classification | Pricing, Forecasting |\n",
    "\n",
    "### Real-World Deployment Considerations\n",
    "\n",
    "1. **Regulatory Compliance**:\n",
    "   - Insurance regulations vary by state\n",
    "   - Model fairness and bias considerations\n",
    "   - Explainability requirements\n",
    "   - Actuarial review needed\n",
    "\n",
    "2. **Model Maintenance**:\n",
    "   - Regular retraining with new data\n",
    "   - Monitor prediction accuracy\n",
    "   - Track actual vs predicted costs\n",
    "   - Update for healthcare cost inflation\n",
    "\n",
    "3. **Integration**:\n",
    "   - API for quote requests\n",
    "   - Real-time predictions (<100ms)\n",
    "   - Error handling\n",
    "   - Logging and monitoring\n",
    "\n",
    "4. **User Experience**:\n",
    "   - Instant quotes\n",
    "   - Explanations for pricing\n",
    "   - What-if scenarios\n",
    "   - Comparison shopping\n",
    "\n",
    "### Limitations and Future Work\n",
    "\n",
    "1. **Current Limitations**:\n",
    "   - Limited to 6 features (many factors affect costs)\n",
    "   - No medical history details\n",
    "   - No pre-existing conditions\n",
    "   - Simplified model of complex reality\n",
    "\n",
    "2. **Potential Improvements**:\n",
    "   - Add medical history variables\n",
    "   - Include prescription drug costs\n",
    "   - Account for family medical history\n",
    "   - Regional healthcare provider costs\n",
    "   - Lifestyle factors (exercise, diet)\n",
    "\n",
    "3. **Advanced Techniques**:\n",
    "   - Neural networks for complex interactions\n",
    "   - Bayesian methods for uncertainty quantification\n",
    "   - Causal inference for interventions\n",
    "   - Time series for cost trends\n",
    "\n",
    "### Resources for Further Learning\n",
    "\n",
    "- [PyCaret Regression Tutorial](https://pycaret.gitbook.io/docs/get-started/tutorials/regression)\n",
    "- [Regression Analysis Fundamentals](https://scikit-learn.org/stable/modules/linear_model.html)\n",
    "- [Insurance Analytics](https://www.coursera.org/)\n",
    "- [Healthcare Cost Analysis](https://www.kaggle.com/learn)\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Bala Anbalagan  \n",
    "**Date**: January 2025  \n",
    "**Dataset**: [Kaggle - Medical Insurance Cost Dataset](https://www.kaggle.com/datasets/mirichoi0218/insurance)  \n",
    "**License**: MIT  \n",
    "\n",
    "---\n",
    "\n",
    "## Thank you for following this regression tutorial!\n",
    "\n",
    "**Key Achievement**: We successfully predicted insurance costs in dollars using automated machine learning!\n",
    "\n",
    "**Main Insight**: Smoking status is by far the strongest predictor of insurance costs, followed by age and BMI.\n",
    "\n",
    "**Next Steps**:\n",
    "- Try with your own pricing dataset\n",
    "- Experiment with feature engineering\n",
    "- Deploy in a web application\n",
    "\n",
    "**Disclaimer**: This model is for educational purposes. Real insurance pricing involves actuarial science, regulatory compliance, and many more factors. Always consult qualified actuaries and comply with insurance regulations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}