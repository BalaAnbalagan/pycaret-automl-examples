{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection: Network Intrusion Detection using PyCaret\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/BalaAnbalagan/pycaret-automl-examples/blob/main/anomaly-detection/network_intrusion_detection.ipynb)\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Cybersecurity threats are constantly evolving. Network intrusion detection systems (NIDS) must identify anomalous network traffic that could indicate attacks, malware, or unauthorized access. This is an **unsupervised anomaly detection** problem - we don't have labels for all attack types, but we need to flag unusual behavior.\n",
    "\n",
    "## Business Value\n",
    "\n",
    "- **Cybersecurity**: Detect zero-day attacks and unknown threats\n",
    "- **Network Operations**: Identify performance anomalies\n",
    "- **Compliance**: Meet security monitoring requirements\n",
    "- **Incident Response**: Early warning system for breaches\n",
    "- **Cost Savings**: Prevent data breaches and downtime\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "**Source**: [Kaggle - Network Intrusion Detection (2024)](https://www.kaggle.com/datasets/bcccdatasets/network-intrusion-detection)\n",
    "\n",
    "**Original**: Based on CIC-IDS-2017 dataset\n",
    "\n",
    "**Features**: Network traffic characteristics including:\n",
    "- Flow duration\n",
    "- Packet counts and sizes\n",
    "- Bytes per second\n",
    "- Flag counts (SYN, ACK, FIN, etc.)\n",
    "- Protocol information\n",
    "\n",
    "**Task**: Identify anomalous network flows (potential attacks)\n",
    "\n",
    "## What You Will Learn\n",
    "\n",
    "1. **Anomaly Detection**: Finding outliers in data\n",
    "2. **Unsupervised Learning**: No labeled attacks needed\n",
    "3. **Multiple Algorithms**: Isolation Forest, LOF, One-Class SVM\n",
    "4. **Anomaly Scoring**: Ranking suspicious activity\n",
    "5. **Threshold Selection**: Balancing false positives vs false negatives\n",
    "6. **Cybersecurity Application**: Real-world threat detection\n",
    "7. **Model Deployment**: Production intrusion detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## Cell 1: Install and Import Required Libraries (Google Colab Compatible)\n\n### What\nWe're installing PyCaret with compatible dependencies for Google Colab and importing all necessary Python libraries for our analysis.\n\n### Why\nGoogle Colab comes with pre-installed packages that can conflict with PyCaret's dependencies. This cell ensures compatibility by installing packages in the correct order to avoid runtime crashes.\n\n### Technical Details\n- Detect if running in Google Colab\n- Install compatible versions of base packages (numpy, pandas, scipy, scikit-learn)\n- Install PyCaret without forcing full dependency resolution\n- Avoid version conflicts that cause runtime crashes\n\n### Expected Output\nInstallation progress messages and a reminder to restart the runtime. After restart, the notebook will work smoothly without dependency errors.\n\n### IMPORTANT\nâš ï¸ After running this cell, you MUST restart the runtime:\n- Click: **Runtime â†’ Restart runtime** (or Ctrl+M .)\n- After restart, skip this cell and run all other cells normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n# INSTALLATION CELL - Google Colab Compatible\n# ============================================================\n# This cell fixes dependency conflicts that cause runtime crashes\n\nimport sys\n\n# Check if running in Colab\nIN_COLAB = 'google.colab' in sys.modules\n\nif IN_COLAB:\n    print(\"=\" * 60)\n    print(\"ðŸ”§ Google Colab Detected\")\n    print(\"=\" * 60)\n    print(\"ðŸ“¦ Installing PyCaret with compatible dependencies...\")\n    print(\"â³ This will take 2-3 minutes, please be patient...",
    "\")\n\n    # Upgrade pip first\n    !pip install -q --upgrade pip\n\n    # Install compatible base packages FIRST (prevents conflicts)\n    print(\"Step 1/3: Installing base packages with compatible versions...\")\n    !pip install -q --upgrade \\\n        numpy>=1.23.0,<2.0.0 \\\n        pandas>=2.0.0,<2.3.0 \\\n        scipy>=1.10.0,<1.14.0 \\\n        scikit-learn>=1.3.0,<1.6.0 \\\n        matplotlib>=3.7.0,<3.9.0\n\n    # Install PyCaret (will use already installed base packages)\n    print(\"Step 2/3: Installing PyCaret...\")\n    !pip install -q pycaret\n\n    # Install additional ML packages\n    print(\"Step 3/3: Installing additional ML packages...\")\n    !pip install -q \\\n        category-encoders \\\n        lightgbm \\\n        xgboost \\\n        catboost \\\n        optuna \\\n        plotly \\\n        kaleido\n\n    print(\"",
    "\" + \"=\" * 60)\n    print(\"âœ… Installation Complete!\")\n    print(\"=\" * 60)\n    print(\"",
    "âš ï¸  CRITICAL: You MUST restart the runtime now!\")\n    print(\"   ðŸ‘‰ Click: Runtime â†’ Restart runtime (or Ctrl+M .)",
    "\")\n    print(\"ðŸ”„ After restart:\")\n    print(\"   1. Skip this installation cell\")\n    print(\"   2. Run all other cells normally\")\n    print(\"   3. Everything will work without crashes!",
    "\")\n    print(\"=\" * 60)\n\nelse:\n    print(\"=\" * 60)\n    print(\"ðŸ“ Local Environment Detected\")\n    print(\"=\" * 60)\n    print(\"Installing standard PyCaret with full dependencies...",
    "\")\n    !pip install pycaret[full]\n    print(\"",
    "âœ… Installation complete!\")\n    print(\"=\" * 60)\n\n# Import libraries after installation\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set visualization style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (10, 6)\n\nprint(\"",
    "ðŸ“š Libraries imported successfully!\")\nprint(f\"   - Pandas version: {pd.__version__}\")\nprint(f\"   - NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 2: Load Network Traffic Dataset\n",
    "\n",
    "### What\n",
    "Loading network traffic data for anomaly detection.\n",
    "\n",
    "### Why\n",
    "For demonstration, we'll use a sample dataset. In production:\n",
    "- Real-time network packet capture\n",
    "- Feature extraction from flow data\n",
    "- Continuous monitoring\n",
    "\n",
    "### Technical Details\n",
    "Network traffic features capture flow characteristics that can reveal attacks.\n",
    "\n",
    "### Expected Output\n",
    "Dataset loaded with network flow features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demo, we'll create a synthetic network traffic dataset\n",
    "# In production, use actual network flow data\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate normal network traffic (90%)\n",
    "n_normal = 900\n",
    "normal_data = {\n",
    "    'flow_duration': np.random.normal(120000, 30000, n_normal),\n",
    "    'total_fwd_packets': np.random.poisson(50, n_normal),\n",
    "    'total_bwd_packets': np.random.poisson(45, n_normal),\n",
    "    'flow_bytes_per_sec': np.random.normal(5000, 1000, n_normal),\n",
    "    'flow_packets_per_sec': np.random.normal(100, 20, n_normal),\n",
    "    'fwd_header_length': np.random.normal(200, 50, n_normal),\n",
    "    'bwd_header_length': np.random.normal(180, 40, n_normal)\n",
    "}\n",
    "\n",
    "# Generate anomalous traffic (10% - attacks, scans, etc.)\n",
    "n_anomaly = 100\n",
    "anomaly_data = {\n",
    "    'flow_duration': np.random.normal(5000, 2000, n_anomaly),  # Very short\n",
    "    'total_fwd_packets': np.random.poisson(200, n_anomaly),  # Unusually high\n",
    "    'total_bwd_packets': np.random.poisson(5, n_anomaly),  # Unusually low\n",
    "    'flow_bytes_per_sec': np.random.normal(50000, 10000, n_anomaly),  # Very high\n",
    "    'flow_packets_per_sec': np.random.normal(500, 100, n_anomaly),  # Very high\n",
    "    'fwd_header_length': np.random.normal(400, 100, n_anomaly),  # High\n",
    "    'bwd_header_length': np.random.normal(50, 20, n_anomaly)  # Low\n",
    "}\n",
    "\n",
    "# Combine and create DataFrame\n",
    "df_normal = pd.DataFrame(normal_data)\n",
    "df_anomaly = pd.DataFrame(anomaly_data)\n",
    "df = pd.concat([df_normal, df_anomaly], ignore_index=True)\n",
    "\n",
    "# Shuffle\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Add true labels (for evaluation only - not used in training)\n",
    "true_labels = [0]*n_normal + [1]*n_anomaly\n",
    "df['true_anomaly'] = true_labels\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Network traffic dataset created!\")\n",
    "print(f\"\\nShape: {df.shape[0]} network flows, {df.shape[1]-1} features\")\n",
    "print(f\"\\nTrue distribution (for evaluation):\")\n",
    "print(f\"- Normal traffic: {(df['true_anomaly']==0).sum()}\")\n",
    "print(f\"- Anomalous traffic: {(df['true_anomaly']==1).sum()}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 3: Exploratory Data Analysis\n",
    "\n",
    "### What\n",
    "Exploring network traffic patterns to understand normal vs anomalous behavior.\n",
    "\n",
    "### Why\n",
    "Understanding data helps:\n",
    "- Identify features that distinguish anomalies\n",
    "- Set realistic expectations\n",
    "- Guide algorithm selection\n",
    "\n",
    "### Technical Details\n",
    "We'll visualize distributions to see if anomalies are visually distinct.\n",
    "\n",
    "### Expected Output\n",
    "Statistical summary and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"NETWORK TRAFFIC ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Remove true_anomaly for unsupervised analysis\n",
    "features_df = df.drop('true_anomaly', axis=1)\n",
    "\n",
    "print(\"\\nStatistical Summary:\")\n",
    "display(features_df.describe())\n",
    "\n",
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(features_df.columns):\n",
    "    axes[idx].hist(features_df[col], bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[idx].set_title(col, fontsize=10, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Value')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[7])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- Most traffic follows normal patterns (main distribution)\")\n",
    "print(\"- Some outliers visible (potential anomalies)\")\n",
    "print(\"- Different features show different spread\")\n",
    "print(\"- Anomaly detection will flag unusual combinations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 4: PyCaret Setup for Anomaly Detection\n",
    "\n",
    "### What\n",
    "Initializing PyCaret's anomaly detection environment.\n",
    "\n",
    "### Why\n",
    "Anomaly detection setup prepares data for:\n",
    "- Outlier identification\n",
    "- Anomaly scoring\n",
    "- Threshold-based flagging\n",
    "\n",
    "### Technical Details\n",
    "Like clustering, anomaly detection is unsupervised:\n",
    "- No target variable\n",
    "- No train/test split (use all data)\n",
    "- Normalization important\n",
    "\n",
    "### Expected Output\n",
    "Setup summary for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.anomaly import *\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PYCARET SETUP - ANOMALY DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nConfiguring unsupervised anomaly detection...\\n\")\n",
    "\n",
    "# Setup (exclude true_anomaly from training)\n",
    "anomaly_setup = setup(\n",
    "    data=features_df,\n",
    "    normalize=True,\n",
    "    session_seed=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ“ Anomaly detection setup complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nKey Points:\")\n",
    "print(\"- UNSUPERVISED: No labels used in training\")\n",
    "print(\"- GOAL: Flag unusual network flows\")\n",
    "print(\"- ASSUMPTION: Most traffic is normal, anomalies are rare\")\n",
    "print(\"\\nReady to detect network intrusions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 5: Create Anomaly Detection Models\n",
    "\n",
    "### What\n",
    "Creating multiple anomaly detection models with different algorithms.\n",
    "\n",
    "### Why\n",
    "Different algorithms detect different types of anomalies:\n",
    "\n",
    "**Isolation Forest**:\n",
    "- Fast and scalable\n",
    "- Isolates anomalies using random trees\n",
    "- Good for high-dimensional data\n",
    "\n",
    "**LOF (Local Outlier Factor)**:\n",
    "- Density-based detection\n",
    "- Compares local density to neighbors\n",
    "- Good for varying density clusters\n",
    "\n",
    "**One-Class SVM**:\n",
    "- Learns boundary around normal data\n",
    "- Flags points outside boundary\n",
    "- Good for well-defined normal region\n",
    "\n",
    "### Technical Details\n",
    "Each algorithm assigns anomaly scores and labels.\n",
    "\n",
    "### Expected Output\n",
    "Models created with anomaly detection results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CREATING ANOMALY DETECTION MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Isolation Forest\n",
    "print(\"\\n1. Isolation Forest\")\n",
    "print(\"   - Fast, scalable algorithm\")\n",
    "print(\"   - Isolates anomalies using random trees\")\n",
    "iforest = create_model('iforest', fraction=0.1)\n",
    "\n",
    "# LOF (Local Outlier Factor)\n",
    "print(\"\\n2. Local Outlier Factor (LOF)\")\n",
    "print(\"   - Density-based detection\")\n",
    "print(\"   - Compares local density to neighbors\")\n",
    "lof = create_model('lof', fraction=0.1)\n",
    "\n",
    "# One-Class SVM\n",
    "print(\"\\n3. One-Class SVM\")\n",
    "print(\"   - Learns boundary around normal data\")\n",
    "print(\"   - Flags outliers outside boundary\")\n",
    "ocsvm = create_model('svm', fraction=0.1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"All models created!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNote: 'fraction=0.1' means expect ~10% anomalies\")\n",
    "print(\"Adjust based on your network's typical anomaly rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 6: Assign Anomaly Labels and Scores\n",
    "\n",
    "### What\n",
    "Assigning anomaly labels (0=normal, 1=anomaly) and scores to each network flow.\n",
    "\n",
    "### Why\n",
    "Anomaly detection output includes:\n",
    "- **Binary label**: Normal (0) or Anomaly (1)\n",
    "- **Anomaly score**: Continuous score (higher = more anomalous)\n",
    "- **Decision function**: Distance from normal region\n",
    "\n",
    "### Technical Details\n",
    "Scores allow ranking:\n",
    "- Investigate highest-scoring flows first\n",
    "- Adjust thresholds based on resources\n",
    "- Create priority alerts\n",
    "\n",
    "### Expected Output\n",
    "Dataset with anomaly predictions and scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ASSIGNING ANOMALY LABELS AND SCORES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Assign predictions (using Isolation Forest)\n",
    "predictions = assign_model(iforest)\n",
    "\n",
    "# Add true labels for evaluation\n",
    "predictions['true_anomaly'] = df['true_anomaly'].values\n",
    "\n",
    "print(\"\\nPredictions completed!\")\n",
    "print(f\"\\nColumns added:\")\n",
    "print(\"- Anomaly: Binary label (0=Normal, 1=Anomaly)\")\n",
    "print(\"- Anomaly_Score: Continuous score (higher = more suspicious)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DETECTION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal flows analyzed: {len(predictions)}\")\n",
    "print(f\"Flagged as anomalies: {(predictions['Anomaly']==1).sum()}\")\n",
    "print(f\"Marked as normal: {(predictions['Anomaly']==0).sum()}\")\n",
    "\n",
    "print(\"\\nSample predictions (sorted by anomaly score):\")\n",
    "display(predictions[['flow_duration', 'total_fwd_packets', 'Anomaly', 'Anomaly_Score', 'true_anomaly']]\n",
    "        .sort_values('Anomaly_Score', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 7: Evaluate Detection Performance\n",
    "\n",
    "### What\n",
    "Evaluating how well our model detects true anomalies (since we have ground truth for this demo).\n",
    "\n",
    "### Why\n",
    "In production, we don't have labels, but for this demo:\n",
    "- Check if model catches real attacks\n",
    "- Understand false positive rate\n",
    "- Validate approach before deployment\n",
    "\n",
    "### Technical Details\n",
    "Key metrics:\n",
    "- **Precision**: Of flagged flows, how many are truly anomalous?\n",
    "- **Recall**: Of true anomalies, how many did we catch?\n",
    "- **F1-Score**: Balance between precision and recall\n",
    "\n",
    "### Expected Output\n",
    "Confusion matrix and performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ANOMALY DETECTION PERFORMANCE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNote: In production, we don't have true labels.\")\n",
    "print(\"This evaluation is possible because we created synthetic data.\\n\")\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(predictions['true_anomaly'], predictions['Anomaly'],\n",
    "                          target_names=['Normal', 'Anomaly']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(predictions['true_anomaly'], predictions['Anomaly'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Normal', 'Anomaly'],\n",
    "            yticklabels=['Normal', 'Anomaly'])\n",
    "plt.title('Confusion Matrix - Anomaly Detection', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFUSION MATRIX BREAKDOWN\")\n",
    "print(\"=\" * 60)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nTrue Negatives (TN):  {tn} - Correctly identified normal traffic\")\n",
    "print(f\"False Positives (FP): {fp} - False alarms (normal flagged as anomaly)\")\n",
    "print(f\"False Negatives (FN): {fn} - Missed attacks (anomaly marked as normal) âš ï¸\")\n",
    "print(f\"True Positives (TP):  {tp} - Correctly caught anomalies âœ“\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CYBERSECURITY PERSPECTIVE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n- False Positives (FP): Alert fatigue, wasted investigation time\")\n",
    "print(\"- False Negatives (FN): Missed threats - MOST CRITICAL!\")\n",
    "print(\"\\nTrade-off: Lower threshold = More FP but fewer FN (catch more attacks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 8: Visualize Anomalies\n",
    "\n",
    "### What\n",
    "Visualizing detected anomalies in 2D space using dimensionality reduction.\n",
    "\n",
    "### Why\n",
    "Helps understand:\n",
    "- Where anomalies lie in feature space\n",
    "- If they form patterns\n",
    "- Model behavior\n",
    "\n",
    "### Technical Details\n",
    "PCA or t-SNE reduces dimensions for visualization.\n",
    "\n",
    "### Expected Output\n",
    "2D plot showing normal vs anomalous flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"VISUALIZING ANOMALIES IN 2D\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# PyCaret's built-in visualization\n",
    "plot_model(iforest, plot='tsne')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INTERPRETING THE VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n- Blue points: Normal network traffic\")\n",
    "print(\"- Red/Yellow points: Detected anomalies\")\n",
    "print(\"- t-SNE reduces 7 dimensions to 2D\")\n",
    "print(\"\\nGood detection shows:\")\n",
    "print(\"- Anomalies at edges/outside main cluster\")\n",
    "print(\"- Clear separation from normal traffic\")\n",
    "print(\"- Some clustering of similar attack types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 9: Analyze Top Anomalies\n",
    "\n",
    "### What\n",
    "Examining the most suspicious network flows for investigation.\n",
    "\n",
    "### Why\n",
    "In production:\n",
    "- Security teams investigate top-scoring flows first\n",
    "- Limited resources require prioritization\n",
    "- Understanding patterns helps create rules\n",
    "\n",
    "### Technical Details\n",
    "Sort by anomaly score to get most suspicious flows.\n",
    "\n",
    "### Expected Output\n",
    "List of highest-scoring anomalies with characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TOP 10 MOST SUSPICIOUS NETWORK FLOWS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get top anomalies\n",
    "top_anomalies = predictions[predictions['Anomaly']==1].sort_values('Anomaly_Score', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nThese flows should be investigated first:\\n\")\n",
    "display(top_anomalies[['flow_duration', 'total_fwd_packets', 'total_bwd_packets',\n",
    "                       'flow_bytes_per_sec', 'Anomaly_Score', 'true_anomaly']])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CHARACTERISTICS OF DETECTED ANOMALIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "anomalies_only = predictions[predictions['Anomaly']==1].drop(['Anomaly', 'Anomaly_Score', 'true_anomaly'], axis=1)\n",
    "normal_only = predictions[predictions['Anomaly']==0].drop(['Anomaly', 'Anomaly_Score', 'true_anomaly'], axis=1)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Feature': anomalies_only.columns,\n",
    "    'Normal_Mean': normal_only.mean().values,\n",
    "    'Anomaly_Mean': anomalies_only.mean().values\n",
    "})\n",
    "comparison['Difference_%'] = ((comparison['Anomaly_Mean'] - comparison['Normal_Mean']) / \n",
    "                               comparison['Normal_Mean'] * 100).round(1)\n",
    "\n",
    "print(\"\\nAverage values: Normal vs Anomalous traffic\")\n",
    "display(comparison)\n",
    "\n",
    "print(\"\\nKey patterns in anomalies:\")\n",
    "for idx, row in comparison.iterrows():\n",
    "    if abs(row['Difference_%']) > 50:\n",
    "        direction = \"higher\" if row['Difference_%'] > 0 else \"lower\"\n",
    "        print(f\"- {row['Feature']}: {abs(row['Difference_%']):.1f}% {direction} than normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 10: Save Anomaly Detection Model\n",
    "\n",
    "### What\n",
    "Saving the trained anomaly detection model for deployment.\n",
    "\n",
    "### Why\n",
    "Production deployment:\n",
    "- Real-time network monitoring\n",
    "- Continuous threat detection\n",
    "- Automated alerting\n",
    "- Integration with SIEM systems\n",
    "\n",
    "### Technical Details\n",
    "Model can score new flows in real-time.\n",
    "\n",
    "### Expected Output\n",
    "Saved model ready for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SAVING ANOMALY DETECTION MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model_name = 'network_intrusion_detector'\n",
    "save_model(iforest, model_name)\n",
    "\n",
    "print(f\"\\nâœ“ Model saved as '{model_name}.pkl'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DEPLOYMENT ARCHITECTURE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. Network Traffic Capture\")\n",
    "print(\"   â†“ Extract flow features\")\n",
    "print(\"2. Feature Engineering\")\n",
    "print(\"   â†“ Normalize, transform\")\n",
    "print(\"3. Anomaly Detection Model\")\n",
    "print(\"   â†“ Score each flow\")\n",
    "print(\"4. Alert System\")\n",
    "print(\"   â†“ High scores trigger alerts\")\n",
    "print(\"5. Security Team Investigation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PRODUCTION CONSIDERATIONS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n- Set appropriate anomaly threshold based on team capacity\")\n",
    "print(\"- Implement alert prioritization (score-based)\")\n",
    "print(\"- Regular model retraining with new normal traffic\")\n",
    "print(\"- Feedback loop: Confirmed attacks improve model\")\n",
    "print(\"- Integration with firewall for automatic blocking\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TO USE THE MODEL\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n```python\")\n",
    "print(\"from pycaret.anomaly import load_model, predict_model\")\n",
    "print(f\"model = load_model('{model_name}')\")\n",
    "print(\"predictions = predict_model(model, data=new_traffic)\")\n",
    "print(\"suspicious = predictions[predictions['Anomaly']==1]\")\n",
    "print(\"```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusions and Key Takeaways\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "1. **Anomaly Detection**: Identified unusual network traffic patterns\n",
    "2. **Unsupervised Learning**: No labeled attacks needed for training\n",
    "3. **Multiple Algorithms**: Compared Isolation Forest, LOF, One-Class SVM\n",
    "4. **Anomaly Scoring**: Ranked suspicious flows for investigation\n",
    "5. **Production Ready**: Model ready for real-time intrusion detection\n",
    "\n",
    "### Key Learnings\n",
    "\n",
    "#### Anomaly Detection vs Other ML Tasks\n",
    "\n",
    "| Aspect | Classification | Clustering | Anomaly Detection |\n",
    "|--------|---------------|-----------|------------------|\n",
    "| Goal | Predict labels | Find groups | Find outliers |\n",
    "| Labels | Required | None | None |\n",
    "| Output | Class | Cluster ID | Anomaly score |\n",
    "| Assumption | Balanced classes | Natural groups | Most data is normal |\n",
    "| Use Case | Diagnosis | Segmentation | Fraud, intrusion |\n",
    "\n",
    "#### Technical Skills\n",
    "- **Isolation Forest**: Fast, scalable outlier detection\n",
    "- **LOF**: Density-based anomaly detection\n",
    "- **One-Class SVM**: Boundary-based detection\n",
    "- **Anomaly Scoring**: Continuous scores for prioritization\n",
    "- **Threshold Selection**: Balancing false positives vs false negatives\n",
    "\n",
    "#### Cybersecurity Applications\n",
    "- **Network Intrusion Detection**: Flag suspicious traffic\n",
    "- **Zero-Day Attacks**: Detect unknown threats\n",
    "- **Insider Threats**: Unusual user behavior\n",
    "- **DDoS Detection**: Abnormal traffic patterns\n",
    "- **Malware Detection**: Anomalous system behavior\n",
    "\n",
    "### Anomaly Detection Algorithms\n",
    "\n",
    "**Isolation Forest**:\n",
    "- **How**: Isolates anomalies using random trees\n",
    "- **Strengths**: Fast, scalable, handles high dimensions\n",
    "- **Best for**: Large datasets, real-time detection\n",
    "\n",
    "**Local Outlier Factor (LOF)**:\n",
    "- **How**: Compares local density to neighbors\n",
    "- **Strengths**: Good for varying density regions\n",
    "- **Best for**: Complex data with multiple normal patterns\n",
    "\n",
    "**One-Class SVM**:\n",
    "- **How**: Learns boundary around normal data\n",
    "- **Strengths**: Effective for well-defined normal region\n",
    "- **Best for**: High-dimensional data with clear normal zone\n",
    "\n",
    "### Business Value\n",
    "\n",
    "1. **Security**:\n",
    "   - Early threat detection\n",
    "   - Reduced dwell time\n",
    "   - Proactive defense\n",
    "\n",
    "2. **Cost Savings**:\n",
    "   - Prevent data breaches ($millions)\n",
    "   - Reduce manual monitoring\n",
    "   - Minimize downtime\n",
    "\n",
    "3. **Compliance**:\n",
    "   - Meet security monitoring requirements\n",
    "   - Audit trail of threats\n",
    "   - Demonstrate due diligence\n",
    "\n",
    "### Challenges and Considerations\n",
    "\n",
    "1. **False Positives**:\n",
    "   - Alert fatigue if too many\n",
    "   - Wasted investigation time\n",
    "   - Need to tune threshold\n",
    "\n",
    "2. **False Negatives**:\n",
    "   - Missed attacks are costly\n",
    "   - More dangerous than false positives\n",
    "   - Balance with other security layers\n",
    "\n",
    "3. **Concept Drift**:\n",
    "   - Normal traffic patterns change\n",
    "   - New attack types emerge\n",
    "   - Regular retraining needed\n",
    "\n",
    "### Production Deployment\n",
    "\n",
    "**Real-time Pipeline**:\n",
    "1. Capture network packets\n",
    "2. Extract flow features\n",
    "3. Normalize/preprocess\n",
    "4. Score with model\n",
    "5. Alert if anomaly\n",
    "6. Investigate and respond\n",
    "\n",
    "**Best Practices**:\n",
    "- Start with conservative threshold (fewer alerts)\n",
    "- Gradually tune based on investigation feedback\n",
    "- Implement tiered alerting (critical/medium/low)\n",
    "- Integrate with SIEM for correlation\n",
    "- Regular model updates with new normal traffic\n",
    "- Maintain human-in-the-loop for critical decisions\n",
    "\n",
    "### Limitations\n",
    "\n",
    "1. **Training Data Quality**:\n",
    "   - Assumes training data is mostly normal\n",
    "   - Contaminated training = poor detection\n",
    "\n",
    "2. **Novel Attacks**:\n",
    "   - Can miss sophisticated attacks that mimic normal traffic\n",
    "   - Should be one layer in defense-in-depth strategy\n",
    "\n",
    "3. **Feature Engineering**:\n",
    "   - Quality of features crucial\n",
    "   - Domain expertise needed\n",
    "\n",
    "### Future Enhancements\n",
    "\n",
    "1. **Deep Learning**: Neural networks for complex patterns\n",
    "2. **Ensemble Methods**: Combine multiple detectors\n",
    "3. **Temporal Analysis**: Sequence-based detection\n",
    "4. **Contextual Features**: User, time, location context\n",
    "5. **Active Learning**: Feedback from investigations\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [PyCaret Anomaly Detection](https://pycaret.gitbook.io/docs/get-started/tutorials/anomaly-detection)\n",
    "- [Scikit-learn Outlier Detection](https://scikit-learn.org/stable/modules/outlier_detection.html)\n",
    "- [Network Intrusion Detection](https://www.coursera.org/)\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Bala Anbalagan  \n",
    "**Date**: January 2025  \n",
    "**Dataset**: Synthetic network traffic (based on CIC-IDS-2017 patterns)  \n",
    "**License**: MIT  \n",
    "\n",
    "---\n",
    "\n",
    "## Thank you for following this anomaly detection tutorial!\n",
    "\n",
    "**Key Achievement**: Built an unsupervised intrusion detection system without labeled attacks!\n",
    "\n",
    "**Main Insight**: Anomaly detection excels at finding unusual patterns, making it perfect for cybersecurity where new threats constantly emerge.\n",
    "\n",
    "**Next Steps**:\n",
    "- Apply to real network traffic data\n",
    "- Integrate with SIEM systems\n",
    "- Deploy for continuous monitoring\n",
    "\n",
    "**Disclaimer**: For educational purposes. Production intrusion detection requires comprehensive security architecture, not just anomaly detection. Always combine with firewalls, IDS/IPS, endpoint protection, and security expertise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}