{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection: Network Intrusion Detection using PyCaret\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/BalaAnbalagan/pycaret-automl-examples/blob/main/anomaly-detection/network_intrusion_detection.ipynb)\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Cybersecurity threats are constantly evolving. Network intrusion detection systems (NIDS) must identify anomalous network traffic that could indicate attacks, malware, or unauthorized access. This is an **unsupervised anomaly detection** problem - we don't have labels for all attack types, but we need to flag unusual behavior.\n",
    "\n",
    "## Business Value\n",
    "\n",
    "- **Cybersecurity**: Detect zero-day attacks and unknown threats\n",
    "- **Network Operations**: Identify performance anomalies\n",
    "- **Compliance**: Meet security monitoring requirements\n",
    "- **Incident Response**: Early warning system for breaches\n",
    "- **Cost Savings**: Prevent data breaches and downtime\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "**Source**: [Kaggle - Network Intrusion Detection (2024)](https://www.kaggle.com/datasets/bcccdatasets/network-intrusion-detection)\n",
    "\n",
    "**Original**: Based on CIC-IDS-2017 dataset\n",
    "\n",
    "**Features**: Network traffic characteristics including:\n",
    "- Flow duration\n",
    "- Packet counts and sizes\n",
    "- Bytes per second\n",
    "- Flag counts (SYN, ACK, FIN, etc.)\n",
    "- Protocol information\n",
    "\n",
    "**Task**: Identify anomalous network flows (potential attacks)\n",
    "\n",
    "## What You Will Learn\n",
    "\n",
    "1. **Anomaly Detection**: Finding outliers in data\n",
    "2. **Unsupervised Learning**: No labeled attacks needed\n",
    "3. **Multiple Algorithms**: Isolation Forest, LOF, One-Class SVM\n",
    "4. **Anomaly Scoring**: Ranking suspicious activity\n",
    "5. **Threshold Selection**: Balancing false positives vs false negatives\n",
    "6. **Cybersecurity Application**: Real-world threat detection\n",
    "7. **Model Deployment**: Production intrusion detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n## Cell 1: Install and Import Required Libraries (Google Colab Compatible)\n\n### What\nWe're installing PyCaret with compatible dependencies for Google Colab and importing all necessary Python libraries for our analysis.\n\n### Why\nGoogle Colab comes with pre-installed packages that can conflict with PyCaret's dependencies. This cell ensures compatibility by installing packages in the correct order to avoid runtime crashes.\n\n### Technical Details\n- Detect if running in Google Colab\n- Install compatible versions of base packages (numpy, pandas, scipy, scikit-learn)\n- Install PyCaret without forcing full dependency resolution\n- Avoid version conflicts that cause runtime crashes\n\n### Expected Output\nInstallation progress messages and a reminder to restart the runtime. After restart, the notebook will work smoothly without dependency errors.\n\n### IMPORTANT\n⚠️ After running this cell, you MUST restart the runtime:\n- Click: **Runtime → Restart runtime** (or Ctrl+M .)\n- After restart, skip this cell and run all other cells normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n# INSTALLATION CELL - Google Colab Compatible\n# ============================================================\n# This cell fixes dependency conflicts that cause runtime crashes\n\nimport sys\n\n# Check if running in Colab\nIN_COLAB = 'google.colab' in sys.modules\n\nif IN_COLAB:\n    print(\"=\" * 60)\n    print(\"🔧 Google Colab Detected\")\n    print(\"=\" * 60)\n    print(\"📦 Installing PyCaret with compatible dependencies...\")\n    print(\"⏳ This will take 2-3 minutes, please be patient...",
    "\")\n\n    # Upgrade pip first\n    !pip install -q --upgrade pip\n\n    # Install compatible base packages FIRST (prevents conflicts)\n    print(\"Step 1/3: Installing base packages with compatible versions...\")\n    !pip install -q --upgrade \\\n        numpy>=1.23.0,<2.0.0 \\\n        pandas>=2.0.0,<2.3.0 \\\n        scipy>=1.10.0,<1.14.0 \\\n        scikit-learn>=1.3.0,<1.6.0 \\\n        matplotlib>=3.7.0,<3.9.0\n\n    # Install PyCaret (will use already installed base packages)\n    print(\"Step 2/3: Installing PyCaret...\")\n    !pip install -q pycaret\n\n    # Install additional ML packages\n    print(\"Step 3/3: Installing additional ML packages...\")\n    !pip install -q \\\n        category-encoders \\\n        lightgbm \\\n        xgboost \\\n        catboost \\\n        optuna \\\n        plotly \\\n        kaleido\n\n    print(\"",
    "\" + \"=\" * 60)\n    print(\"✅ Installation Complete!\")\n    print(\"=\" * 60)\n    print(\"",
    "⚠️  CRITICAL: You MUST restart the runtime now!\")\n    print(\"   👉 Click: Runtime → Restart runtime (or Ctrl+M .)",
    "\")\n    print(\"🔄 After restart:\")\n    print(\"   1. Skip this installation cell\")\n    print(\"   2. Run all other cells normally\")\n    print(\"   3. Everything will work without crashes!",
    "\")\n    print(\"=\" * 60)\n\nelse:\n    print(\"=\" * 60)\n    print(\"📍 Local Environment Detected\")\n    print(\"=\" * 60)\n    print(\"Installing standard PyCaret with full dependencies...",
    "\")\n    !pip install pycaret[full]\n    print(\"",
    "✅ Installation complete!\")\n    print(\"=\" * 60)\n\n# Import libraries after installation\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set visualization style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (10, 6)\n\nprint(\"",
    "📚 Libraries imported successfully!\")\nprint(f\"   - Pandas version: {pd.__version__}\")\nprint(f\"   - NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 2: Load Network Traffic Dataset\n",
    "\n",
    "### What\n",
    "Loading network traffic data for anomaly detection.\n",
    "\n",
    "### Why\n",
    "For demonstration, we'll use a sample dataset. In production:\n",
    "- Real-time network packet capture\n",
    "- Feature extraction from flow data\n",
    "- Continuous monitoring\n",
    "\n",
    "### Technical Details\n",
    "Network traffic features capture flow characteristics that can reveal attacks.\n",
    "\n",
    "### Expected Output\n",
    "Dataset loaded with network flow features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demo, we'll create a synthetic network traffic dataset\n",
    "# In production, use actual network flow data\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate normal network traffic (90%)\n",
    "n_normal = 900\n",
    "normal_data = {\n",
    "    'flow_duration': np.random.normal(120000, 30000, n_normal),\n",
    "    'total_fwd_packets': np.random.poisson(50, n_normal),\n",
    "    'total_bwd_packets': np.random.poisson(45, n_normal),\n",
    "    'flow_bytes_per_sec': np.random.normal(5000, 1000, n_normal),\n",
    "    'flow_packets_per_sec': np.random.normal(100, 20, n_normal),\n",
    "    'fwd_header_length': np.random.normal(200, 50, n_normal),\n",
    "    'bwd_header_length': np.random.normal(180, 40, n_normal)\n",
    "}\n",
    "\n",
    "# Generate anomalous traffic (10% - attacks, scans, etc.)\n",
    "n_anomaly = 100\n",
    "anomaly_data = {\n",
    "    'flow_duration': np.random.normal(5000, 2000, n_anomaly),  # Very short\n",
    "    'total_fwd_packets': np.random.poisson(200, n_anomaly),  # Unusually high\n",
    "    'total_bwd_packets': np.random.poisson(5, n_anomaly),  # Unusually low\n",
    "    'flow_bytes_per_sec': np.random.normal(50000, 10000, n_anomaly),  # Very high\n",
    "    'flow_packets_per_sec': np.random.normal(500, 100, n_anomaly),  # Very high\n",
    "    'fwd_header_length': np.random.normal(400, 100, n_anomaly),  # High\n",
    "    'bwd_header_length': np.random.normal(50, 20, n_anomaly)  # Low\n",
    "}\n",
    "\n",
    "# Combine and create DataFrame\n",
    "df_normal = pd.DataFrame(normal_data)\n",
    "df_anomaly = pd.DataFrame(anomaly_data)\n",
    "df = pd.concat([df_normal, df_anomaly], ignore_index=True)\n",
    "\n",
    "# Shuffle\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Add true labels (for evaluation only - not used in training)\n",
    "true_labels = [0]*n_normal + [1]*n_anomaly\n",
    "df['true_anomaly'] = true_labels\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Network traffic dataset created!\")\n",
    "print(f\"\\nShape: {df.shape[0]} network flows, {df.shape[1]-1} features\")\n",
    "print(f\"\\nTrue distribution (for evaluation):\")\n",
    "print(f\"- Normal traffic: {(df['true_anomaly']==0).sum()}\")\n",
    "print(f\"- Anomalous traffic: {(df['true_anomaly']==1).sum()}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 3: Exploratory Data Analysis\n",
    "\n",
    "### What\n",
    "Exploring network traffic patterns to understand normal vs anomalous behavior.\n",
    "\n",
    "### Why\n",
    "Understanding data helps:\n",
    "- Identify features that distinguish anomalies\n",
    "- Set realistic expectations\n",
    "- Guide algorithm selection\n",
    "\n",
    "### Technical Details\n",
    "We'll visualize distributions to see if anomalies are visually distinct.\n",
    "\n",
    "### Expected Output\n",
    "Statistical summary and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"NETWORK TRAFFIC ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Remove true_anomaly for unsupervised analysis\n",
    "features_df = df.drop('true_anomaly', axis=1)\n",
    "\n",
    "print(\"\\nStatistical Summary:\")\n",
    "display(features_df.describe())\n",
    "\n",
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(features_df.columns):\n",
    "    axes[idx].hist(features_df[col], bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[idx].set_title(col, fontsize=10, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Value')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[7])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observations:\")\n",
    "print(\"- Most traffic follows normal patterns (main distribution)\")\n",
    "print(\"- Some outliers visible (potential anomalies)\")\n",
    "print(\"- Different features show different spread\")\n",
    "print(\"- Anomaly detection will flag unusual combinations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 4: PyCaret Setup for Anomaly Detection\n",
    "\n",
    "### What\n",
    "Initializing PyCaret's anomaly detection environment.\n",
    "\n",
    "### Why\n",
    "Anomaly detection setup prepares data for:\n",
    "- Outlier identification\n",
    "- Anomaly scoring\n",
    "- Threshold-based flagging\n",
    "\n",
    "### Technical Details\n",
    "Like clustering, anomaly detection is unsupervised:\n",
    "- No target variable\n",
    "- No train/test split (use all data)\n",
    "- Normalization important\n",
    "\n",
    "### Expected Output\n",
    "Setup summary for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.anomaly import *\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PYCARET SETUP - ANOMALY DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nConfiguring unsupervised anomaly detection...\\n\")\n",
    "\n",
    "# Setup (exclude true_anomaly from training)\n",
    "anomaly_setup = setup(\n",
    "    data=features_df,\n",
    "    normalize=True,\n",
    "    session_seed=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"✓ Anomaly detection setup complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nKey Points:\")\n",
    "print(\"- UNSUPERVISED: No labels used in training\")\n",
    "print(\"- GOAL: Flag unusual network flows\")\n",
    "print(\"- ASSUMPTION: Most traffic is normal, anomalies are rare\")\n",
    "print(\"\\nReady to detect network intrusions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 5: Create Anomaly Detection Models\n",
    "\n",
    "### What\n",
    "Creating multiple anomaly detection models with different algorithms.\n",
    "\n",
    "### Why\n",
    "Different algorithms detect different types of anomalies:\n",
    "\n",
    "**Isolation Forest**:\n",
    "- Fast and scalable\n",
    "- Isolates anomalies using random trees\n",
    "- Good for high-dimensional data\n",
    "\n",
    "**LOF (Local Outlier Factor)**:\n",
    "- Density-based detection\n",
    "- Compares local density to neighbors\n",
    "- Good for varying density clusters\n",
    "\n",
    "**One-Class SVM**:\n",
    "- Learns boundary around normal data\n",
    "- Flags points outside boundary\n",
    "- Good for well-defined normal region\n",
    "\n",
    "### Technical Details\n",
    "Each algorithm assigns anomaly scores and labels.\n",
    "\n",
    "### Expected Output\n",
    "Models created with anomaly detection results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CREATING ANOMALY DETECTION MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Isolation Forest\n",
    "print(\"\\n1. Isolation Forest\")\n",
    "print(\"   - Fast, scalable algorithm\")\n",
    "print(\"   - Isolates anomalies using random trees\")\n",
    "iforest = create_model('iforest', fraction=0.1)\n",
    "\n",
    "# LOF (Local Outlier Factor)\n",
    "print(\"\\n2. Local Outlier Factor (LOF)\")\n",
    "print(\"   - Density-based detection\")\n",
    "print(\"   - Compares local density to neighbors\")\n",
    "lof = create_model('lof', fraction=0.1)\n",
    "\n",
    "# One-Class SVM\n",
    "print(\"\\n3. One-Class SVM\")\n",
    "print(\"   - Learns boundary around normal data\")\n",
    "print(\"   - Flags outliers outside boundary\")\n",
    "ocsvm = create_model('svm', fraction=0.1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"All models created!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNote: 'fraction=0.1' means expect ~10% anomalies\")\n",
    "print(\"Adjust based on your network's typical anomaly rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 6: Assign Anomaly Labels and Scores\n",
    "\n",
    "### What\n",
    "Assigning anomaly labels (0=normal, 1=anomaly) and scores to each network flow.\n",
    "\n",
    "### Why\n",
    "Anomaly detection output includes:\n",
    "- **Binary label**: Normal (0) or Anomaly (1)\n",
    "- **Anomaly score**: Continuous score (higher = more anomalous)\n",
    "- **Decision function**: Distance from normal region\n",
    "\n",
    "### Technical Details\n",
    "Scores allow ranking:\n",
    "- Investigate highest-scoring flows first\n",
    "- Adjust thresholds based on resources\n",
    "- Create priority alerts\n",
    "\n",
    "### Expected Output\n",
    "Dataset with anomaly predictions and scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ASSIGNING ANOMALY LABELS AND SCORES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Assign predictions (using Isolation Forest)\n",
    "predictions = assign_model(iforest)\n",
    "\n",
    "# Add true labels for evaluation\n",
    "predictions['true_anomaly'] = df['true_anomaly'].values\n",
    "\n",
    "print(\"\\nPredictions completed!\")\n",
    "print(f\"\\nColumns added:\")\n",
    "print(\"- Anomaly: Binary label (0=Normal, 1=Anomaly)\")\n",
    "print(\"- Anomaly_Score: Continuous score (higher = more suspicious)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DETECTION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal flows analyzed: {len(predictions)}\")\n",
    "print(f\"Flagged as anomalies: {(predictions['Anomaly']==1).sum()}\")\n",
    "print(f\"Marked as normal: {(predictions['Anomaly']==0).sum()}\")\n",
    "\n",
    "print(\"\\nSample predictions (sorted by anomaly score):\")\n",
    "display(predictions[['flow_duration', 'total_fwd_packets', 'Anomaly', 'Anomaly_Score', 'true_anomaly']]\n",
    "        .sort_values('Anomaly_Score', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 7: Evaluate Detection Performance\n",
    "\n",
    "### What\n",
    "Evaluating how well our model detects true anomalies (since we have ground truth for this demo).\n",
    "\n",
    "### Why\n",
    "In production, we don't have labels, but for this demo:\n",
    "- Check if model catches real attacks\n",
    "- Understand false positive rate\n",
    "- Validate approach before deployment\n",
    "\n",
    "### Technical Details\n",
    "Key metrics:\n",
    "- **Precision**: Of flagged flows, how many are truly anomalous?\n",
    "- **Recall**: Of true anomalies, how many did we catch?\n",
    "- **F1-Score**: Balance between precision and recall\n",
    "\n",
    "### Expected Output\n",
    "Confusion matrix and performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ANOMALY DETECTION PERFORMANCE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNote: In production, we don't have true labels.\")\n",
    "print(\"This evaluation is possible because we created synthetic data.\\n\")\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(predictions['true_anomaly'], predictions['Anomaly'],\n",
    "                          target_names=['Normal', 'Anomaly']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(predictions['true_anomaly'], predictions['Anomaly'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Normal', 'Anomaly'],\n",
    "            yticklabels=['Normal', 'Anomaly'])\n",
    "plt.title('Confusion Matrix - Anomaly Detection', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFUSION MATRIX BREAKDOWN\")\n",
    "print(\"=\" * 60)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nTrue Negatives (TN):  {tn} - Correctly identified normal traffic\")\n",
    "print(f\"False Positives (FP): {fp} - False alarms (normal flagged as anomaly)\")\n",
    "print(f\"False Negatives (FN): {fn} - Missed attacks (anomaly marked as normal) ⚠️\")\n",
    "print(f\"True Positives (TP):  {tp} - Correctly caught anomalies ✓\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CYBERSECURITY PERSPECTIVE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n- False Positives (FP): Alert fatigue, wasted investigation time\")\n",
    "print(\"- False Negatives (FN): Missed threats - MOST CRITICAL!\")\n",
    "print(\"\\nTrade-off: Lower threshold = More FP but fewer FN (catch more attacks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 8: Visualize Anomalies\n",
    "\n",
    "### What\n",
    "Visualizing detected anomalies in 2D space using dimensionality reduction.\n",
    "\n",
    "### Why\n",
    "Helps understand:\n",
    "- Where anomalies lie in feature space\n",
    "- If they form patterns\n",
    "- Model behavior\n",
    "\n",
    "### Technical Details\n",
    "PCA or t-SNE reduces dimensions for visualization.\n",
    "\n",
    "### Expected Output\n",
    "2D plot showing normal vs anomalous flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"VISUALIZING ANOMALIES IN 2D\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# PyCaret's built-in visualization\n",
    "plot_model(iforest, plot='tsne')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"INTERPRETING THE VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n- Blue points: Normal network traffic\")\n",
    "print(\"- Red/Yellow points: Detected anomalies\")\n",
    "print(\"- t-SNE reduces 7 dimensions to 2D\")\n",
    "print(\"\\nGood detection shows:\")\n",
    "print(\"- Anomalies at edges/outside main cluster\")\n",
    "print(\"- Clear separation from normal traffic\")\n",
    "print(\"- Some clustering of similar attack types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 9: Analyze Top Anomalies\n",
    "\n",
    "### What\n",
    "Examining the most suspicious network flows for investigation.\n",
    "\n",
    "### Why\n",
    "In production:\n",
    "- Security teams investigate top-scoring flows first\n",
    "- Limited resources require prioritization\n",
    "- Understanding patterns helps create rules\n",
    "\n",
    "### Technical Details\n",
    "Sort by anomaly score to get most suspicious flows.\n",
    "\n",
    "### Expected Output\n",
    "List of highest-scoring anomalies with characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TOP 10 MOST SUSPICIOUS NETWORK FLOWS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get top anomalies\n",
    "top_anomalies = predictions[predictions['Anomaly']==1].sort_values('Anomaly_Score', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nThese flows should be investigated first:\\n\")\n",
    "display(top_anomalies[['flow_duration', 'total_fwd_packets', 'total_bwd_packets',\n",
    "                       'flow_bytes_per_sec', 'Anomaly_Score', 'true_anomaly']])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CHARACTERISTICS OF DETECTED ANOMALIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "anomalies_only = predictions[predictions['Anomaly']==1].drop(['Anomaly', 'Anomaly_Score', 'true_anomaly'], axis=1)\n",
    "normal_only = predictions[predictions['Anomaly']==0].drop(['Anomaly', 'Anomaly_Score', 'true_anomaly'], axis=1)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Feature': anomalies_only.columns,\n",
    "    'Normal_Mean': normal_only.mean().values,\n",
    "    'Anomaly_Mean': anomalies_only.mean().values\n",
    "})\n",
    "comparison['Difference_%'] = ((comparison['Anomaly_Mean'] - comparison['Normal_Mean']) / \n",
    "                               comparison['Normal_Mean'] * 100).round(1)\n",
    "\n",
    "print(\"\\nAverage values: Normal vs Anomalous traffic\")\n",
    "display(comparison)\n",
    "\n",
    "print(\"\\nKey patterns in anomalies:\")\n",
    "for idx, row in comparison.iterrows():\n",
    "    if abs(row['Difference_%']) > 50:\n",
    "        direction = \"higher\" if row['Difference_%'] > 0 else \"lower\"\n",
    "        print(f\"- {row['Feature']}: {abs(row['Difference_%']):.1f}% {direction} than normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell 10: Save Anomaly Detection Model\n",
    "\n",
    "### What\n",
    "Saving the trained anomaly detection model for deployment.\n",
    "\n",
    "### Why\n",
    "Production deployment:\n",
    "- Real-time network monitoring\n",
    "- Continuous threat detection\n",
    "- Automated alerting\n",
    "- Integration with SIEM systems\n",
    "\n",
    "### Technical Details\n",
    "Model can score new flows in real-time.\n",
    "\n",
    "### Expected Output\n",
    "Saved model ready for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SAVING ANOMALY DETECTION MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model_name = 'network_intrusion_detector'\n",
    "save_model(iforest, model_name)\n",
    "\n",
    "print(f\"\\n✓ Model saved as '{model_name}.pkl'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DEPLOYMENT ARCHITECTURE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. Network Traffic Capture\")\n",
    "print(\"   ↓ Extract flow features\")\n",
    "print(\"2. Feature Engineering\")\n",
    "print(\"   ↓ Normalize, transform\")\n",
    "print(\"3. Anomaly Detection Model\")\n",
    "print(\"   ↓ Score each flow\")\n",
    "print(\"4. Alert System\")\n",
    "print(\"   ↓ High scores trigger alerts\")\n",
    "print(\"5. Security Team Investigation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PRODUCTION CONSIDERATIONS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n- Set appropriate anomaly threshold based on team capacity\")\n",
    "print(\"- Implement alert prioritization (score-based)\")\n",
    "print(\"- Regular model retraining with new normal traffic\")\n",
    "print(\"- Feedback loop: Confirmed attacks improve model\")\n",
    "print(\"- Integration with firewall for automatic blocking\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TO USE THE MODEL\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n```python\")\n",
    "print(\"from pycaret.anomaly import load_model, predict_model\")\n",
    "print(f\"model = load_model('{model_name}')\")\n",
    "print(\"predictions = predict_model(model, data=new_traffic)\")\n",
    "print(\"suspicious = predictions[predictions['Anomaly']==1]\")\n",
    "print(\"```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusions and Key Takeaways\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "1. **Anomaly Detection**: Identified unusual network traffic patterns\n",
    "2. **Unsupervised Learning**: No labeled attacks needed for training\n",
    "3. **Multiple Algorithms**: Compared Isolation Forest, LOF, One-Class SVM\n",
    "4. **Anomaly Scoring**: Ranked suspicious flows for investigation\n",
    "5. **Production Ready**: Model ready for real-time intrusion detection\n",
    "\n",
    "### Key Learnings\n",
    "\n",
    "#### Anomaly Detection vs Other ML Tasks\n",
    "\n",
    "| Aspect | Classification | Clustering | Anomaly Detection |\n",
    "|--------|---------------|-----------|------------------|\n",
    "| Goal | Predict labels | Find groups | Find outliers |\n",
    "| Labels | Required | None | None |\n",
    "| Output | Class | Cluster ID | Anomaly score |\n",
    "| Assumption | Balanced classes | Natural groups | Most data is normal |\n",
    "| Use Case | Diagnosis | Segmentation | Fraud, intrusion |\n",
    "\n",
    "#### Technical Skills\n",
    "- **Isolation Forest**: Fast, scalable outlier detection\n",
    "- **LOF**: Density-based anomaly detection\n",
    "- **One-Class SVM**: Boundary-based detection\n",
    "- **Anomaly Scoring**: Continuous scores for prioritization\n",
    "- **Threshold Selection**: Balancing false positives vs false negatives\n",
    "\n",
    "#### Cybersecurity Applications\n",
    "- **Network Intrusion Detection**: Flag suspicious traffic\n",
    "- **Zero-Day Attacks**: Detect unknown threats\n",
    "- **Insider Threats**: Unusual user behavior\n",
    "- **DDoS Detection**: Abnormal traffic patterns\n",
    "- **Malware Detection**: Anomalous system behavior\n",
    "\n",
    "### Anomaly Detection Algorithms\n",
    "\n",
    "**Isolation Forest**:\n",
    "- **How**: Isolates anomalies using random trees\n",
    "- **Strengths**: Fast, scalable, handles high dimensions\n",
    "- **Best for**: Large datasets, real-time detection\n",
    "\n",
    "**Local Outlier Factor (LOF)**:\n",
    "- **How**: Compares local density to neighbors\n",
    "- **Strengths**: Good for varying density regions\n",
    "- **Best for**: Complex data with multiple normal patterns\n",
    "\n",
    "**One-Class SVM**:\n",
    "- **How**: Learns boundary around normal data\n",
    "- **Strengths**: Effective for well-defined normal region\n",
    "- **Best for**: High-dimensional data with clear normal zone\n",
    "\n",
    "### Business Value\n",
    "\n",
    "1. **Security**:\n",
    "   - Early threat detection\n",
    "   - Reduced dwell time\n",
    "   - Proactive defense\n",
    "\n",
    "2. **Cost Savings**:\n",
    "   - Prevent data breaches ($millions)\n",
    "   - Reduce manual monitoring\n",
    "   - Minimize downtime\n",
    "\n",
    "3. **Compliance**:\n",
    "   - Meet security monitoring requirements\n",
    "   - Audit trail of threats\n",
    "   - Demonstrate due diligence\n",
    "\n",
    "### Challenges and Considerations\n",
    "\n",
    "1. **False Positives**:\n",
    "   - Alert fatigue if too many\n",
    "   - Wasted investigation time\n",
    "   - Need to tune threshold\n",
    "\n",
    "2. **False Negatives**:\n",
    "   - Missed attacks are costly\n",
    "   - More dangerous than false positives\n",
    "   - Balance with other security layers\n",
    "\n",
    "3. **Concept Drift**:\n",
    "   - Normal traffic patterns change\n",
    "   - New attack types emerge\n",
    "   - Regular retraining needed\n",
    "\n",
    "### Production Deployment\n",
    "\n",
    "**Real-time Pipeline**:\n",
    "1. Capture network packets\n",
    "2. Extract flow features\n",
    "3. Normalize/preprocess\n",
    "4. Score with model\n",
    "5. Alert if anomaly\n",
    "6. Investigate and respond\n",
    "\n",
    "**Best Practices**:\n",
    "- Start with conservative threshold (fewer alerts)\n",
    "- Gradually tune based on investigation feedback\n",
    "- Implement tiered alerting (critical/medium/low)\n",
    "- Integrate with SIEM for correlation\n",
    "- Regular model updates with new normal traffic\n",
    "- Maintain human-in-the-loop for critical decisions\n",
    "\n",
    "### Limitations\n",
    "\n",
    "1. **Training Data Quality**:\n",
    "   - Assumes training data is mostly normal\n",
    "   - Contaminated training = poor detection\n",
    "\n",
    "2. **Novel Attacks**:\n",
    "   - Can miss sophisticated attacks that mimic normal traffic\n",
    "   - Should be one layer in defense-in-depth strategy\n",
    "\n",
    "3. **Feature Engineering**:\n",
    "   - Quality of features crucial\n",
    "   - Domain expertise needed\n",
    "\n",
    "### Future Enhancements\n",
    "\n",
    "1. **Deep Learning**: Neural networks for complex patterns\n",
    "2. **Ensemble Methods**: Combine multiple detectors\n",
    "3. **Temporal Analysis**: Sequence-based detection\n",
    "4. **Contextual Features**: User, time, location context\n",
    "5. **Active Learning**: Feedback from investigations\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [PyCaret Anomaly Detection](https://pycaret.gitbook.io/docs/get-started/tutorials/anomaly-detection)\n",
    "- [Scikit-learn Outlier Detection](https://scikit-learn.org/stable/modules/outlier_detection.html)\n",
    "- [Network Intrusion Detection](https://www.coursera.org/)\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Bala Anbalagan  \n",
    "**Date**: January 2025  \n",
    "**Dataset**: Synthetic network traffic (based on CIC-IDS-2017 patterns)  \n",
    "**License**: MIT  \n",
    "\n",
    "---\n",
    "\n",
    "## Thank you for following this anomaly detection tutorial!\n",
    "\n",
    "**Key Achievement**: Built an unsupervised intrusion detection system without labeled attacks!\n",
    "\n",
    "**Main Insight**: Anomaly detection excels at finding unusual patterns, making it perfect for cybersecurity where new threats constantly emerge.\n",
    "\n",
    "**Next Steps**:\n",
    "- Apply to real network traffic data\n",
    "- Integrate with SIEM systems\n",
    "- Deploy for continuous monitoring\n",
    "\n",
    "**Disclaimer**: For educational purposes. Production intrusion detection requires comprehensive security architecture, not just anomaly detection. Always combine with firewalls, IDS/IPS, endpoint protection, and security expertise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}